<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="ar">
  <head>
    <meta charset="utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>1. مقدّمة &#8212; تعمّق في التعلّم العميق 0.7.1 documentation</title>

    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script type="text/javascript" src="../_static/d2l.js"></script>
    <script type="text/javascript" src="../_static/translations.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. التمهيدات" href="../chapter_preliminaries/index.html" />
    <link rel="prev" title="الّرموز" href="../chapter_notation/index.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header "><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link is-active"><span class="section-number">1. </span>مقدّمة</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_introduction/index.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://courses.d2l.ai">
                  <i class="fas fa-user-graduate"></i>
                  Courses
              </a>
          
              <a  class="mdl-navigation__link" href="https://d2l.ai/d2l-en.pdf">
                  <i class="fas fa-file-pdf"></i>
                  PDF
              </a>
          
              <a  class="mdl-navigation__link" href="https://d2l.ai/d2l-en.zip">
                  <i class="fas fa-download"></i>
                  All Notebooks
              </a>
          
              <a  class="mdl-navigation__link" href="https://discuss.mxnet.io">
                  <i class="fab fa-discourse"></i>
                  Discuss
              </a>
          
              <a  class="mdl-navigation__link" href="https://github.com/d2l-ai/d2l-en">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://zh.d2l.ai">
                  <i class="fas fa-external-link-alt"></i>
                  中文版
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="تعمّق في التعلّم العميق"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">الّرموز</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">1. مقدّمة</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. التمهيدات</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-math-and-keywords-translations/index.html">3. ملحق: ترجمة الألفاظ التقنية و الرياضية</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">المراجع</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <img class="logo" src="../_static/logo-with-text.png" alt="تعمّق في التعلّم العميق"/>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preface/index.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_notation/index.html">الّرموز</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">1. مقدّمة</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_preliminaries/index.html">2. التمهيدات</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chapter_appendix-math-and-keywords-translations/index.html">3. ملحق: ترجمة الألفاظ التقنية و الرياضية</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">المراجع</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="chap-introduction">
<span id="id1"></span><h1><span class="section-number">1. </span>مقدّمة<a class="headerlink" href="#chap-introduction" title="Permalink to this headline">¶</a></h1>
<p>حتى وقت قريب ، تمّ تطوير كُلّ برنامج الكمبيوتر التّي نتفاعل معها يوميًا
بواسطة مُطوِّري البرامج من المبادئ الأولى للبرمجة. فمثلا لو أردنا كتابة
برنامج لإدارة منصّة تجارة إلكترونية ، سنتبع التّمَشّي التّالي: سنجتمع مع
كل المطوّرين المكلّفين بالمشروع حول لوحة بيضاء لبضع ساعات للتفكير في
جميع ميزات المنصّة و كيفية تفاعلها مع المُستخدم. بعد هذه المرحلة من
التفكير، سنصل إلى عدد كبير من الحلول العمليّة التّي قد تبدو كالتالي: (1)
يتفاعل المستخدمون مع التطبيق من خلال واجهة تعمل في متصفح الويب أو تطبيق
المحمول ؛ (2) يتفاعل تطبيقنا مع محرك قاعدة بيانات من الدرجة التجارية
لتتبُّع حالة كل مستخدم والحفاظ على سجلات معاملاته التاريخية ؛ و (3) في
قلب تطبيقنا، سنفصّل منهجيّة عمل البرنامج في جميع الحالات المُمكنة حتى
تصير مجموعة القواعد هذه <em>كعقل</em> مدبّر للبرنامج حتى يتّخذ الإجراء المناسب
في كُلّ ظرف يمكن تصوُّره.</p>
<p>لبناء <em>العقل المدبّر</em> لتطبيقنا ، كان علينا أن نفكّر في كل حالة ممكنة
نتوقع مواجهتها ، ووضع قواعد مناسبة لها. فمثلا، في كل مرة ينقر فيها
العميل لإضافة منتج إلى سلة التسوق الخاصة به ، نضيف إدخالًا إلى جدول
قاعدة بيانات عربة التسوق ، ونربط معرِّف المستخدم بمعرِّف المنتج المطلوب.
رغم أنّ قلّة من المُطوّرين يمكنهم كتابة كُلّ قواعد هذه المنصّة من دون
أخطاء من المرّة الأولى (فقد يستغرق الأمر القيام ببعض الاختبارات لتجنّب
أيّ خلل ممكن) ، في الأغلب ، يُمكننا كتابة مثل هذا البرنامج من المبادئ
الأولى وإطلاقه بثقة * قبل إختباره مع أيّ عميل حقيقي<em>. تُعد قدرتنا،
هذه، على تصميم أنظمة تلقائية من المبادئ الأولى و التي بإمكانها أن تحرك
المنتجات والأنظمة العاملة ، غالبًا في مواقف جديدة ، قدرة إدراكيًةً
ملحوظًة. و قبل أن نغوص في عالم تعلّم الآلة، إعلم أنّه عندما تكون قادرًا
على ابتكار حلول برمجيّة تعمل بنسبة 100٪ ٪ من الوقت للمشكلة المعروضة
،</em>فيجب ألاَّ تستخدم التعلم الآلي *.</p>
<p>لحُسن حظّ المجتمع المتنامي لعلماء و مختصّي تعلّم الآلة ، فإن العديد من
المهام و المشاكل التي نرغب في تشغيلها أو حلّها تلقائيًا (عبر تطوير برامج
لحلّها) لا تنحني بسهولة للإبداع البشري. فمثلا، تخيّل أن تجمع أذكى العقول
التي تعرفها ، لتعالج إحدى المشاكل التالية:</p>
<ul class="simple">
<li><p>كتابة برنامجٍ يتنبأ بطقس الغد في ضوء مجموعة من المعلومات الجغرافية
وصور الأقمار الصناعية و حالة الطقس في عدد من الأيام السابقة.</p></li>
<li><p>كتابةُ برنامجٍ يأخذ سؤالًا ، معبّرًا عنه بنصّ حرّ ، و يتكمن من
الإجابة عنه بشكل صحيح.</p></li>
<li><p>كتابةُ برنامجٍ يتمكن من تحديد جميع الأشخاص الموجودين في صورة ما ،
ورسم الخطوط العريضة حول مكان وجود كل منهم في الصورة.</p></li>
<li><p>كتابةُ برنامجٍ يقدم للمستخدمين منتجات يُرجّح أن يستمتعوا بها ولكن من
غير المرجّح أن يُصَادفُوها أثناء الاستعراض الطبيعي.</p></li>
</ul>
<p>في كُلّ من هذه الحالات ، لا يمكن ، حتّى لنخبة المبرمجين ، كتابةُ القواعد
اللّازمة لتطوير بَرامج كفيلة بأن تحلّ هذه المشاكل من الصفر. و سبب ذلك قد
يختلف من حالة إلى أخرى. ففي بعض الأحيان يتبع البرنامج الذي نبحث عنه
نمطًا يتغير مع مرور الوقت ، و عندها سيكون على المبرمج تكييف و تحديث
البرنامج كلّما تغييّر. في حالات أخرى ، قد تكون العلاقة (على سبيل المثال
بين البكسلات في صورة ما والفئات المجردة - كالإنسان و السيارة، الخ..)
معقدة للغاية ، حيث أنّ إيجاد هذه العلاقة قد يتطلّب آلاف أو ملايين
الحسابات التي تفوق فهمنا الواعي (حتى لو كانت أعيننا يمكنها أن تقوم بهذه
المهمة دون عناء!).</p>
<p>تعلُّم الآلة (ML) هو دراسة التّقنيات الفعّالة التي يُمكنها أن <em>تتعلم</em> من
<em>التجربة</em>. بالإعتماد على هذه التقنيات، تُرَاكِمُ خوارزميات ML المزيد من
الخبرة ، عادةً في شكل بيانات مراقبة أو تفاعلات مع بيئة معيّنة ، ممّا
يؤدّي إلى تحسين أدائها. قارن هذه التقنيات مع نظام التجارة الإلكترونية
الجامد ، والذي يعمل وفقًا لمنطق الأعمال نفسه ، بغض النظر عن مقدار الخبرة
المكتسبة ، حتى يتعلّم المطورون أنفسهم ويقرروا بأنّ الوقت قد حان لتحديث
البرنامج.</p>
<p>في هذا الكتاب ، سوف نُعلّمك أساسيات تعلّم الآلة ، ونركّز بشكل خاص على
التعلّم العميق ، وهي مجموعة فعّالة من التقنيات التي تقود، في الوقت
الرّاهن، الابتكارات في مجالات متنوعة مثل رؤية الكمبيوتر ، ومعالجة اللغات
الطبيعية ، والرعاية الصحية ، وعلم الجينات.</p>
<p>تَعلُّمُكَ لمُحتوى هذا الكتاب سيفتح لك الباب نحو مجالات عمل متنوّعة و
مشوقة. والأفضل من ذلك أنّه سيفتح أبوابا جديدة للإبداع قد تساعدك ، كما
نرجوا، في تطوير مشاريعك الخاصّة.</p>
<div class="section" id="id2">
<h2><span class="section-number">1.1. </span>مثال تحفيزي<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>قبل أن نتمكن من البدء في كتابة هذا الكتاب كان علينا نأخذ كفايتنا من
القهوة. ثم ركبنا سيارة و بدأنا بالقيادة. باستخدام جهاز iPhone ، أطلق
ألكس (أحدّ المؤلفين) إسم “Hey Siri” ، لإيقاظ نظام التعرّف على الصوت في
هاتفه. ثم أمر مو(مؤلف آخر) الهاتف بعرض “الاتجاهات إلى مقهى Blue Bottle”.
سرعان ما تمكّن الهاتف من تحويل الأمر الشفوي إلى نصّ مكتوب على الشّاشة.
كما أدرك أننا نطلب التوجيهات وأطلق تطبيق الخرائط. بمجرد إطلاق التطبيق ،
حدّد تطبيق الخرائط عددًا من الطرق. بجانب كل مسار ، عرض الهاتف الوقت
المتوقّع لبلوغ المقهى.</p>
<p>على الرغم من أنّنا اخترعنا هذه القصة لغرض تعليميّ ، إلا أنها توضّح أنّه
، خلال بضع ثوانٍ فقط ، يُمكن لتفاعلاتنا اليومية مع الهاتف الذّكي أن
تُشرِكَ العديد من نماذج خوارزميّات تعلّم الآلة.</p>
<p>تخيّل مجرد كتابة برنامج للردّ على كلمة تنبيهٍ * مثل “Alexa” أو “Okay,
Google” أو “Siri”. جرِّب تطوير حلّ لهذا المشكل لوحدك دون أي شيء سوى جهاز
كمبيوتر ومحرّر كود ، كما هو موضح في <a class="reference internal" href="#fig-wake-word"><span class="std std-numref">Fig. 1.1.1</span></a>. كيف تكتب
مثل هذا البرنامج بإستعمال لغة برمجة فقط؟ فكّر في الأمر … المشكلة صعبة.
كل ثانية ، سيجمع الميكروفون حوالي 44000 عيّنة. كل عيّنة هي قياسٌ لسعة
الموجة الصوتية. ما القاعدة التي يمكنّها أن تعيّن من مقتطف الصوت الخام
تنبؤا موثوق به <code class="docutils literal notranslate"><span class="pre">{نعم</span> <span class="pre">،</span> <span class="pre">لا}</span></code> حول ما إذا كان المقتطف يحتوي على كلمة
التنبيه؟ إذا أشكل عليك إيجاد مثل هذه القاعدة ، فلا تقلق. لا نعرف كيفية
كتابة مثل هذا البرنامج من الصفر أيضًا. هذا هو سبب استخدامنا لتعلّم الآلة
ML.</p>
<div class="figure align-default" id="id41">
<span id="fig-wake-word"></span><img alt="../_images/wake-word.svg" src="../_images/wake-word.svg" /><p class="caption"><span class="caption-number">Fig. 1.1.1 </span><span class="caption-text">تحديد كلمة إستيقاظ.</span><a class="headerlink" href="#id41" title="Permalink to this image">¶</a></p>
</div>
<p>كيف نعرف أنّه رغم عدم قدرتنا على كتابة قواعد واضحة لكيفية حلّ المشكل
السابق، يمكن لخوارزميات تعلُّم الآلة أن تجد له حلّا؟</p>
<p>ها هي الحيلة. في كثير من الأحيان ، حتى عندما لا نعرف كيفية إخبار الحاسوب
بشكل صريح عن الطريقة المثلى للتّعيين من المدخلات (inputs) إلى المخرجات
(outputs) ، فنحن قادرون مع ذلك على أداء هذا العمل الإدراكي بأنفسنا.
بمعنى آخر ، حتى لو كنت لا تعرف <em>كيفية برمجة جهاز كمبيوتر</em> للتعرف على
كلمة “Alexa” ، فأنت نفسك <em>قادر على</em> التّعرف على كلمة “Alexa”. مُسلحين
بهذه القدرة ، يمكننا جمع <em>مجموعة بيانات ضخمة</em> تحتوي على أمثلة مختلفة من
الأصوات و تعيين تلك التي <em>تحتوي</em> والتي <em>لا تحتوي</em> على كلمة التنبيه
يدويّا. في مجال تعلُّم الآلة ، لا نحاول تصميم نظام <em>بشكل صريح</em> للتّعرُّف
على كلمات الاستيقاظ. بدلاً من ذلك ، نقوم بتحديد خوارزميّات مرنة يتم
تعديل سلوكها من خلال عدد من <em>المعلمات</em> (أو بارامترات parameters). ثمّ
نستخدم مجموعة البيانات لتحديد أفضل مجموعة ممكنة من المعلمات
(البارامترات) ، التّي تُحسّن أداء البرنامج في المُهمّة المنوطة له.</p>
<p>يمكنُكَ التّفكير في البارامترات كمقابض يُمكن أن نديرها لنغيّر سلوك
البرنامج. عندما نتمّكن من تحديد أفضل بارامترات ، نسمي البرنامج <em>نموذج</em>.
تسمى مجموعة البرامج المختلفة التي يُمكننا إنتاجها عن طريق تغيير المعلمات
<em>عائلة</em> من النماذج. ويطلق على البرنامج الذي يستخدم مجموعة البيانات
المعدّة سباقا لإختيار معلمات النموذج <em>خوارزمية التعلُّم</em>.</p>
<p>قبل أن نتمكن من المضي قدمًا وإشراك خوارزمية التعلم ، يتعين علينا تحديد
المشكلة التّي نريد حلّها بدقة ، وتحديد الطبيعة الدقيقة للمدخلات
والمخرجات ، واختيار عائلة نَمَاذِجَ مناسبة. في هذه الحالة ، يتلقى
نموذجنا مقتطفًا من الصوت كـ <em>إدخال</em> ، ويقوم بالإختيار بين <code class="docutils literal notranslate"><span class="pre">{نعم</span> <span class="pre">،</span> <span class="pre">لا}</span></code>
لتحديد الإخراج المناسب. إذا سارت الأمور وفقًا للخطّة ، فستكون تقديرات
النموذج صحيحة عادةً حول ما إذا كان المقتطف يحتوي على كلمة التنبيه أم لا.</p>
<p>إذا اخترنا عائلة النماذج المناسبة ، فيجب أن يكون هناك إعداد واحد للمقابض
(للبارامترات) بحيث يطلق النموذج <code class="docutils literal notranslate"><span class="pre">نعم</span></code> في كل مرة يسمع فيها كلمة
“Alexa”. نظرًا لأن إختيار كلمة التنبيه هو أمر عشوائي ، فسنحتاج إلى عائلة
نماذج غنية بما يكفي بحيث ، من خلال تغيير وضعيّة المقابض إلى إعداد آخر
مناسب ، يمكن أن تعييّن <code class="docutils literal notranslate"><span class="pre">نعم</span></code> فقط عند سماع كلمة “Apricot”. نتوقع أن
تكون نفس عائلة النماذج مناسبة <em>للتّعرُّف على “Alexa”</em> مناسبة أيضا
<em>للتّعرُّف على “Apricot”</em> لأنّ هاتين المهمّتين تبدوان ، حدسيًا ،
متشابهتين. ومع ذلك ، قد نحتاج إلى مجموعة مختلفة تمامًا من النّماذج إذا
أردنا التّعامل مع مدخلات أو مخرجات مختلفة اختلافًا جذريًا ، فعلى سبيل
المثال إذا كنا نرغب في تعيّين شرح نصّي أو عنوان لصورة ما أو ترجمة أو
تعييّن جمل إنجليزية إلى مرادفاتها في اللغة الصينية.</p>
<p>كما قد تتخيّل ، إذا وضعنا جميع المقابض (المعلمات) بشكل عشوائي ، فمن غير
المحتمل أن يتعرّف نموذجنا على “Alexa” أو “Apricot” أو أي كلمة إنجليزية
أخرى. في التّعلم العميق ، <em>التّعلُّم</em> يشير إلى العمليّة التي نكتشف من
خلالها الإعداد الصحيح للمقابض الذّي يؤدي إلى تحديد النّموذج ذي السلوك
المرغوب فيه.</p>
<p>كما هو موضح في <a class="reference internal" href="#fig-ml-loop"><span class="std std-numref">Fig. 1.1.2</span></a> ، عادةً ما تبدو عمليّة التّدريب
كما يلي:</p>
<ol class="arabic simple">
<li><p>ابدأ بنموذج تمّ تهيئة معلماته (برامتراته) عشوائيًا لذا لا يمكنه فعل
أي شيء مفيد.</p></li>
<li><p>إستعمل بعضا من البيانات الموسّمة سابقا (على سبيل المثال ، مقتطفات
صوتية وما يقابلها من التعيينات <code class="docutils literal notranslate"><span class="pre">{نعم</span> <span class="pre">،</span> <span class="pre">لا}</span></code> للإشارة إلى ما إذا كانت
تحتوي على كلمة التنبيه).</p></li>
<li><p>قم بتغيير المقابض (المعلمات) بحيث يتحسّ أداء النموذج في الأمثلة
المختارة في الخطوة 2.</p></li>
<li><p>كرر هذه الخطوات حتّى يصبح النموذج جيّدا بما فيه الكفاية.</p></li>
</ol>
<div class="figure align-default" id="id42">
<span id="fig-ml-loop"></span><img alt="../_images/ml-loop.svg" src="../_images/ml-loop.svg" /><p class="caption"><span class="caption-number">Fig. 1.1.2 </span><span class="caption-text">عملية تدريب نموذجية.</span><a class="headerlink" href="#id42" title="Permalink to this image">¶</a></p>
</div>
<p>للتّلخيص ، بدلاً من تطوير برنامج للتعرّف على كلمات التنبيه ، نقوم بتطوير
برنامج يمكنه <em>تعلّم</em> كيفية التّعرف على هذه الكلمات ، <em>إذا وفّرنا مجموعة
بيانات كبيرة تحتوي على تعيينات معدّة سابقا</em>. يُمكنك التّفكير في هذه
الطّريقة المتمثّلة في تحديد سلوك البرنامج من خلال تقديم مجموعة بيانات له
كـ <em>برمجةٍ بإستعمالِ البيانات</em>. بإستعمال نفس الطريقة ، يُمكننا “برمجة”
كاشف للقطط من خلال تزويد نظام التّعلم الآلي الخاص بنا بالعديد من الصور
كأمثلة عن القطط و الكلاب ، مثل الصور أدناه:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 21%" />
<col style="width: 26%" />
<col style="width: 26%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>قطّ    |</p></th>
<th class="head"><p>قطّ      |</p></th>
<th class="head"><p>لب      |</p></th>
<th class="head"><p>لب      |</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img alt="cat3" src="../_images/cat3.jpg" /></p></td>
<td><p><img alt="image1" src="../_images/cat2.jpg" /></p></td>
<td><p><img alt="image2" src="../_images/dog1.jpg" /></p></td>
<td><p><img alt="image3" src="../_images/dog2.jpg" /></p></td>
</tr>
</tbody>
</table>
<p>وبهذه الطريقة سيتعلّم الكاشف في النهاية إصدار عدد إيجابي كبير جدًا إذا
كان هناك قطة في الصورة المقدّمة له ، وعددًا سالبًا كبيرًا جدًا إذا كان
هناك كلبٌ ، و عددا أقرب إلى الصفر إذا لم يكن متأكدًا. وهذا بالكاد يخدش
سطح ما يمكن للتعلّم الآلي القيام به.</p>
<p>التّعلم العميق هو واحد من بين العديد من الطرق الشائعة لحلّ مشكلات تعلُّم
الآلة. حتى الآن ، تحدثنا فقط عن التعلّم الآلي على نطاق واسع ولم نتعمّق
في التّعلم العميق. لنَرَى أهميّة التّعلم العميق ، يجب أن نتوقف لِلَحظَةٍ
لتسليط الضوء على بضع نقاط حاسمة.</p>
<p>أولاً ، إنّ المشكلات التي ناقشناها حتى الآن - كالتعلّم من مقاطع صوتية
خام ، أو من قيم البكسل الخام في الصّور ، أو تعلّم التّعيين بين جمل ذات
أطوال عشوائيّة في لغة ما (كالإنجليزية) ونظيراتها في اللغات الأجنبية
(كاللغة العربية أو الصينية) - هي مشاكل يتفوّق فيها التّعلم العميق بعد أن
تعثّرت فيها أساليب تعلّم الآلة التقليدية. النّماذج العميقة <em>عميقة</em>
بالمعنى الدقيق للكلمة لأنها تتعلم العديد من <em>الطبقات</em> الحسابية. اتّضح أن
هذه النماذج متعددة الطبقات (أو الهرميّة) قادرة على معالجة البيانات
الإدراكية منخفضة المستوى بطريقة لم تستطع الأدوات السابقة مجاراتها. في
السابق ، كان الجزء الحاسم لتطبيق خوارزميات التعلّم الآلي على هذه
المشكلات هو التوصّل ، بطرقٍ هندسيةٍ يدويّةٍ ، إلى تحويل البيانات الخام
إلى شكل يمكن للنّماذج <em>الضحلة أو السطحية</em> التعلّم منه. من المزايا
الرئيسية للتّعلم العميق أنه لا يحل محلّ النّماذج <em>الضّحلة</em> فقط في نهاية
مسارات التّعليم الآلي التقليدية ، ولكنه أيضًا يعوّض عملية هندسة
المعلومات يدويا و التّي كانت تتطلّب الكثير من الجهد من الخبراء. ثانياً ،
من خلال استبدال الكثير من <em>المعالجات المسبقة للبيانات و التّي تختلف من
مجال إلى آخر</em> ، أدّى التعلّم العميق إلى القضاء على العديد من الحواجز
التي كانت تفصل سابقًا مجال رؤية الكمبيوتر عن مجال التعرّف على الكلام أو
مجال معالجة اللغات الطبيعية أو حتى عن مجال المعلوماتية الطبية وغيرها من
مجالات تطبيق التعلّم الآلي المختلفة ، ممّا يوفر مجموعة موحدة من الأدوات
من أجل معالجة المشاكل المتنوعة.</p>
</div>
<div class="section" id="id3">
<h2><span class="section-number">1.2. </span>المكوّنات الرّئيسية: البيانات والنماذج والخوارزميات<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>في مثال <em>كلمة التّنبيه</em> ، وصفنا مجموعة بيانات متكوّنة من : (1) مقتطفات
صوتية و (2) تسميات ثنائية (binary labels). كان الهدف من ذلك الوصف تقديم
تفسير إجماليّ لكيفيّة عمل <em>تدريب</em> نماذج التعلّم الآلي لحلّ مشكلة تعيّين
المقاطع الصوتيّة إلي التصنيفات الصحيحة (أي لتحديد ما إذا كان المقطع
الصوتي يحتوي على كلمة تنبيهٍ أم لا). هذا النّوع من المشكلات ، حيث نقوم
بتدريب نموذج تعلّم آليّ بإستعمال مجموعة بيانات، معدّة مسبقا ، متكوّنة من
أمثلة عن <em>المدخلات</em> (inputs) و تسمياتها (labels) الصحيحة ثمّ نقوم
بإستخدامه للتنبؤ بتسمية ، غير معروفة مسبقا ، بناءا على <em>مدخلتها</em>
المعروفة مسبقا ، يسمّى <em>التعلّم تحت الإشراف</em>. و يعدّ التعلّم تحت الإشراف
واحد من بين العديد من أنواع التعلّم الآلي. في القسم التّالي ، سوف نلقي
نظرة أعمق على الأنواع المختلفة للتعلّم الآلي و المشاكل التّي تُستعمل
لحلّها. و لكن ، قبل ذلك ، نريد أن نلقي المزيد من الضوء على بعضٍ من
المكوّنات الأساسية التّي تستعمل في جميع أنواع التعلّم الآلي:</p>
<ol class="arabic simple">
<li><p><em>البيانات</em> التي يمكننا التعلّم منها.</p></li>
<li><p><em>نموذج</em> لكيفية تحويل البيانات.</p></li>
<li><p>دالّة <em>الخسارة</em> (loss function) وهي دالّة تحدد إلى أي مدى النّموذج
<em>سيء</em> في حلّ المشكلة المدروسة.</p></li>
<li><p><em>خوارزمية</em> لتغيير وضبط معلّمات (parameters) النّموذج لتقليل قيمة
دالّة الخسارة.</p></li>
</ol>
<div class="section" id="id4">
<h3><span class="section-number">1.2.1. </span>البيانات<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>من الغنّي عن البيان أنّه لا يمكننا القيام بأي شئ في علم تحليل البيانات
من دون بيانات. قد نملئ العديد من صفحات هذا الكتاب إذا تأمّلنا في كل ما
يمكن اعتباره “بيانات”. و لكن في الوقت الحالي سوف نحيد إلى الجانب العمليّ
و نركّز على الخصائص الرئيسيّة التّي يجب عليك الإهتمام بها. بشكل عام ،
نحن مهتمون بمجموعة من <em>الأمثلة</em> (تسمى أيضًا <em>نقاط البيانات</em> - data
points - أو <em>العيّنات</em> -samples - أو <em>المثيلات</em> - instances). لكي نستخدم
البيانات بشكل مفيد ، نحتاج عادة إلى تحويلها إلي تمثيل رقميّ (numerical
representation) مناسب. عادة ، يتكوّن كُلّ مثال من مجموعة من السّمات
العددية (numerical attributes) تسمّى <em>الميزات</em> (Features). في التعلّم
تحت الإشراف ، يتمّ تعيين ميزة خاصّة <em>كهدف للتنبؤ</em> (Target) ؛ تسمّى أيضا
في بعض الأحيان <em>التسمية</em>(label) أو متغيّر تابع (dependent variable) أو
متغيّر التنبؤ. يمكن عندئذ تسمية كل السّمات المتبقيّة التّي يجب على
النموذج أن يستعملها للقيام بالتنبؤ بإسم <em>ميزات</em> (features) ؛ تسمّي هذه
الميزات أيضا <em>المدخلات</em> (inputs) أو <em>المتغيّرات المستقلّة</em> (independent
variables).</p>
<p>إذا كانت البيانات متكوّنة من مجموعة من الصّور ، فإنّ كُلّ صورة تشكّل
<em>مثالًا</em> ، يتم تمثيل كل منها بقائمة مرتبة من القيم العددية لسطوع كل بكسل
(pixel brightness). تتكون الصورة الملوّنة بحجم $ 200
<a href="#id5"><span class="problematic" id="id6">:raw-latex:`\times `200 $ من :math:`200 \times 200 \times 3 = 120000`</span></a>
قيمة رقمية ، تتوافق مع سطوع القنوات الحمراء و الخضراء و الزرقاء لكل موقع
مكاني. في مهمة أكثر تقليدية ، كمحاولة التنبؤ بما إذا كان مريض ما سيعيش
أم لا ، ستتكوّن البيانات من مجموعة ميزات مختلفة مثل العمر والعلامات
الحيوية وتشخيصات الأطبّاء ، وما إلى ذلك.</p>
<p>عندما يتكوّن كُلّ مثال من نفس العدد من “القيم العددية” ، نقول أن
البيانات تتكون من<em>متجهات ثابتةِ الطُّول</em> و نصف الطول (الثابت) للمتجهات
بأنه <em>عدد أبعاد</em> البيانات. كما قد تتخيل ، يمكن أن يكون الطّول الثابت
لأمثلة البيانات خاصية مريحة. فلو أردنا ، مثلا ، تدريب نموذج للتعرّف على
السرطان في الصور المجهرية ، فإن المدخلات ذات الطول الثابت تقلّل من عدد
المشاكل التّي علينا حلّها لضمان عمل النموذج في أحسن شكل ممكن.</p>
<p>غير أنّه لا يمكن تمثيل جميع البيانات بسهولة كمتجهات ذات طول ثابت. فمثلا
، قد يكون من المنطقيّ أنّ نتوقّع ثبات طول المتجهات القادمة من الصّور
المجهرية لأنّها تأتي من أجهزة ذات مواصفات ثابتة ، إلاّ أنّنا لا نتوقع أن
تكون الصّور المستخرجة من الإنترنت بنفس الدّقة أو الشكل. لحلّ مشكلة
اختلاف الأطوال بالنسبة للصّور ، قد نفكّر في اقتصاصها جميعًا بحجم معيّن ،
لكنّ هذه الاستراتيجية لا تعمل في جميع الأحوال. فنحن نخاطر بفقدان
المعلومات الموجودة في الأجزاء المقطوعة. علاوة على ذلك ، تقاوم البيانات
النصيّة تحويلها إلي متّجهات ذات طول ثابت بعناد أكبر. فمثلا لو نعتبر
مراجعات العملاء (customer reviews) على مواقع التجارة الإلكترونية مثل
Amazon أو IMDB أو TripAdvisor. نجد بعضها قصيرا مثل: “سيئ!” ، وبعضها
الآخر قد يمتدّ لصفحات. تتمثل إحدى الميزات الرئيسية للتعلم العميق ،
بالمقارنة مع الطرق التقليدية للتعلّم الآلي، في السهولة النسبية التي يمكن
للنماذج الحديثة من خلالها التعامل مع البيانات <em>متباينة الطول</em>.</p>
<p>بشكل عام ، كلّما زاد عدد الأمثلة في البيانات المتوفرة لدينا ، أصبح عملنا
أسهل. فعندما يكون لدينا المزيد من البيانات ، يمكننا تدريب نماذج أكثر
دقّة ، والاعتماد بدرجة أقل على الافتراضات المسبقة. يُعدّ الانتقال من
إستعمال بيانات صغيرة نسبيّا إلى إستعمال بيانات كبيرة جدّا (big data)
مساهمًا رئيسيًا في نجاح التعلّم العميق الحديث. و لنبيّن الفكرة تماما ،
فإعلم أنّ العديد من النماذج الأكثر إثارة في التعلّم العميق إمّا لا تعمل
بدون مجموعات بيانات كبيرة ، و إمّا يعمل البعض الآخر مع مجموعات بيانات
صغيرة نسبيّا ، ولكنّ دقّتها ليست أفضل من تلك التّي يمكن الحصول عليها
باستعمال الطّرق التقليدية.</p>
<p>أخيرًا ، لا يكفي الحصول على الكثير من البيانات ومعالجتها بذكاء. نحن
بحاجة إلى البيانات <em>المناسبة</em>. إذا كانت البيانات مليئة بالأخطاء ، أو إذا
كانت الميزات المختارة ليس لها علاقة أو تأثير على هدف التنبّؤ (target) ،
فستفشل عمليّة التعلّم من البيانات . و هذه النتيجة عادة ما يلخّصها
أخصّائيوا التعلّم الآلي بشكل جيد بإستعمال المقولة المشهورة : <em>إذا أدخلت
قمامة ، ستحصل على قمامة كنتيجة</em> (garbage in garbage out). علاوة على ذلك
، فإنّ الأداء الضعيف لعمليّة التنبؤ ليس النّتيجة المحتملة الوحيدة. ففي
التطبيقات الحسّاسة للتعلّم الآلي ، مثل الشرطة التنبؤية (predictive
policing) ، والفحص الآلي للسيرة الذاتية ، ونماذج خطر عدم تسديد الديون
المستخدمة للإقراض ، يجب أن ننتبه بشكل خاص إلى عواقب بيانات السيئة و
التّي مثّلنها بالقمامة سابقا. من الأخطاء الشائعة التّي تؤدّي إلي فشل
التعلّم هو عدم تمثيل بعض مجموعات الأشخاص في بيانات التّدريب. فمثلا ،
تخيّل تطبيق نظام تعرّف على سرطان الجلد لم يسبق له أن يدرّب على بشرة
سمراء. و لا يقتصر الخطأ في نقص تمثيل بعض المجموعات فحسب، و إنّما يتجاوز
ذلك ليصل إلى حدّ إدراج التحيّزات المجتمعية (مثل العنصريّة ضدّ مجموعة ما)
في البيانات. على سبيل المثال ، إذا تم استخدام قرارات التوظيف السابقة
لتدريب نموذج تنبؤي سيتم استخدامه لفحص السّير الذّاتية ، فإن نماذج التعلم
الآلي يمكنها عن غير قصد التقاط المظالم التاريخية و التعلّم منها و
تطبيقها في الحالات المستقبليّة. لاحظ أن كُلّ هذه الأخطاء يمكنها أن تحدث
دون تآمر عالم البيانات ، أو حتى إدراكه بوقوعها.</p>
</div>
<div class="section" id="id7">
<h3><span class="section-number">1.2.2. </span>النّماذج<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>يتضمن معظم التعلّم الآلي <em>تحويل</em> البيانات بطريقة ما. قد نرغب في بناء
نظام يستوعب الصّور ويتوقع مدى <em>ابتسامة</em> الأشخاص فيها. في حالات أخرى ، قد
نرغب في استيعاب مجموعة من قراءات المستشعرات و إستعمالها للتنبؤ بما إذا
كانت قراءة ما <em>عادية</em> أم <em>غير عادية</em>. نشير بكلمة نموذج ، إلى الآلية
الحسابية التّي تستوعب البيانات من نوع ما ، وإطلاق التنبؤات بنوع آخر من
البيانات قد يكون مختلفا. على وجه الخصوص ، نحن مهتمون بالنماذج الإحصائية
التي يمكن تقديرها من خلال البيانات. و في حين أنّ النّماذج البسيطة قادرة
تمامًا على معالجة المشكلات البسيطة بشكل مناسب ، فإنّنا في هذا الكتاب
سنركّز على المشكلات الأكثر تعقيدا و التّي تتجاوز قدرة الطّرق التقليدية.
بشكل أساسي ، يختلف التعلّم العميق عن الطّرق التقليديّة من خلال مجموعة
النّماذج القويّة التّي يركّز عليها. تتكون هذه النماذج من العديد من
التحويلات المتتالية للبيانات المرتبطة معًا من أعلى إلى أسفل ، و هذا
التصميم المتتالي هو ما يعطي هذا المجال إسم <em>التعلّم العميق</em>. في التّالي
، و في طريقنا لمناقشة الشبكات العصبية العميقة ، سنناقش أيضا بعض الطّرق
التقليدية للتعلّم الآلي.</p>
</div>
<div class="section" id="id8">
<h3><span class="section-number">1.2.3. </span>دالّة الهدف<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>سابقا ، قدّمنا التّعلّم الآلي على أنّه “التعلّم من التّجربة”. بكلمة
<em>التعلّم</em> هنا ، نعني <em>تحسين الأداء</em> في مهمّة ما مع مرور الوقت. لكن كيف
يمكننا أن نعرف ما الذّي يشكّل تحسنا ؟ فلو إقترح أحدهم تحديث نموذجنا
بطريقة ما ، قد نختلف معه حول ما إذا كان التّحديث المقترح يشكل تحسينًا أم
تدهورًا.</p>
<p>من أجل تطوير نظام رياضي رسمي للآلات القادرة على التعلّم ، نحتاج إلى ضبط
طريقة قياس رسمية تمكّننا من تحديد مدى صَوَاب أو خطأ النّموذج في المهمّة
المدروسة. في التعلّم الآلي ، و في نظرية الأمثليّة (optimization theory)
بشكل عام ، نسمي طريقة قياس الخطأ <em>دالّة الهدف</em>. إصْطِلاحا ، نحدّد دالّة
الهدف بحيث كلّما كانت قيمتها <em>أصغر</em> كان ذلك <em>أفضل</em> ، وهذه مجرّد اتفاقية.
يمكنك أن تأخذ أي دالّة $ f $ حيث كلّما كبرت قيمتها كان ذلك أفضل ،
وتحوّلها إلى دالّة جديدة <span class="math notranslate nohighlight">\('f\)</span> متطابقة نوعيًا ولكن تدلّ على
الأفضليّة في الإتجاه المعاكس، أي كلّما صغرت قيمتها كان ذلك أفضل ، من
خلال تحديد $ f’ = -f $. لأن الأقل هو الأفضل ، تسمى هذه الدّوالُّ أحيانًا
<em>دوالّ الخسارة</em> أو <em>دوالّ التّكلفة</em>.</p>
<p>عند محاولة التنبؤ بالقيم العدديّة ، دالّة الهدف الأكثر شيوعًا هي <em>الخطأ
التربيعي</em> <span class="math notranslate nohighlight">\((y-\hat{y})^2\)</span> . أمّا فيما يتعلّق بالتّصنيف
(classification) ، فإنّ دالّة الهدف الأكثر شيوعًا هي <em>تقليل معدل الخطأ</em>
إلى الحدّ الأدنى ، أي التقليل أكثر ما يمكن من عدد الحالات التي تختلف
فيها توقعاتنا مع الحقيقة. بعض الأهداف (مثل الخطأ التربيعي) سهلة التحسين.
البعض الآخر (مثل معدّل الخطأ) يصعب تحسينه بشكل مباشر ، بسبب عدم قابليته
للمفاضلة (non-differentiability) و لأسباب أخرى. في هذه الحالات ، من
الشائع تحسين <em>هدف بديل</em>.</p>
<p>Typically, the loss function is defined with respect to the model’s
parameters and depends upon the dataset. The best values of our model’s
parameters are learned by minimizing the loss incurred on a <em>training
set</em> consisting of some number of <em>examples</em> collected for training.
However, doing well on the training data does not guarantee that we will
do well on (unseen) test data. So we will typically want to split the
available data into two partitions: the training data (for fitting model
parameters) and the test data (which is held out for evaluation),
reporting the following two quantities:</p>
<ul class="simple">
<li><p><strong>Training Error:</strong> The error on that data on which the model was
trained. You could think of this as being like a student’s scores on
practice exams used to prepare for some real exam. Even if the
results are encouraging, that does not guarantee success on the final
exam.</p></li>
<li><p><strong>Test Error:</strong> This is the error incurred on an unseen test set.
This can deviate significantly from the training error. When a model
performs well on the training data but fails to generalize to unseen
data, we say that it is <em>overfitting</em>. In real-life terms, this is
like flunking the real exam despite doing well on practice exams.</p></li>
</ul>
</div>
<div class="section" id="id9">
<h3><span class="section-number">1.2.4. </span>خوارزميات التّحسين<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>Once we have got some data source and representation, a model, and a
well-defined objective function, we need an algorithm capable of
searching for the best possible parameters for minimizing the loss
function. The most popular optimization algorithms for neural networks
follow an approach called gradient descent. In short, at each step, they
check to see, for each parameter, which way the training set loss would
move if you perturbed that parameter just a small amount. They then
update the parameter in the direction that reduces the loss.</p>
</div>
</div>
<div class="section" id="id10">
<h2><span class="section-number">1.3. </span>أنواع التعلّم الآلى<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<p>In the following sections, we discuss a few <em>kinds</em> of machine learning
problems in greater detail. We begin with a list of <em>objectives</em>, i.e.,
a list of things that we would like machine learning to do. Note that
the objectives are complemented with a set of techniques of <em>how</em> to
accomplish them, including types of data, models, training techniques,
etc. The list below is just a sampling of the problems ML can tackle to
motivate the reader and provide us with some common language for when we
talk about more problems throughout the book.</p>
<div class="section" id="id11">
<h3><span class="section-number">1.3.1. </span>التعلّم تحت الإشراف<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>Supervised learning addresses the task of predicting <em>targets</em> given
<em>inputs</em>. The targets, which we often call <em>labels</em>, are generally
denoted by <em>y</em>. The input data, also called the <em>features</em> or
covariates, are typically denoted <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Each (input,
target) pair is called an <em>examples</em> or an <em>instances</em>. Some times, when
the context is clear, we may use the term examples, to refer to a
collection of inputs, even when the corresponding targets are unknown.
We denote any particular instance with a subscript, typically <span class="math notranslate nohighlight">\(i\)</span>,
for instance (<span class="math notranslate nohighlight">\(\mathbf{x}_i, y_i\)</span>). A dataset is a collection of
<span class="math notranslate nohighlight">\(n\)</span> instances <span class="math notranslate nohighlight">\(\{\mathbf{x}_i, y_i\}_{i=1}^n\)</span>. Our goal is
to produce a model <span class="math notranslate nohighlight">\(f_\theta\)</span> that maps any input
<span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> to a prediction <span class="math notranslate nohighlight">\(f_{\theta}(\mathbf{x}_i)\)</span>.</p>
<p>To ground this description in a concrete example, if we were working in
healthcare, then we might want to predict whether or not a patient would
have a heart attack. This observation, <em>heart attack</em> or <em>no heart
attack</em>, would be our label <span class="math notranslate nohighlight">\(y\)</span>. The input data <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>
might be vital signs such as heart rate, diastolic and systolic blood
pressure, etc.</p>
<p>The supervision comes into play because for choosing the parameters
<span class="math notranslate nohighlight">\(\theta\)</span>, we (the supervisors) provide the model with a dataset
consisting of <em>labeled examples</em> (<span class="math notranslate nohighlight">\(\mathbf{x}_i, y_i\)</span>), where each
example <span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> is matched with the correct label.</p>
<p>In probabilistic terms, we typically are interested in estimating the
conditional probability <span class="math notranslate nohighlight">\(P(y|x)\)</span>. While it is just one among
several paradigms within machine learning, supervised learning accounts
for the majority of successful applications of machine learning in
industry. Partly, that is because many important tasks can be described
crisply as estimating the probability of something unknown given a
particular set of available data:</p>
<ul class="simple">
<li><p>Predict cancer vs not cancer, given a CT image.</p></li>
<li><p>Predict the correct translation in French, given a sentence in
English.</p></li>
<li><p>Predict the price of a stock next month based on this month’s
financial reporting data.</p></li>
</ul>
<p>Even with the simple description “predict targets from inputs”
supervised learning can take a great many forms and require a great many
modeling decisions, depending on (among other considerations) the type,
size, and the number of inputs and outputs. For example, we use
different models to process sequences (like strings of text or time
series data) and for processing fixed-length vector representations. We
will visit many of these problems in depth throughout the first 9 parts
of this book.</p>
<p>Informally, the learning process looks something like this: Grab a big
collection of examples for which the covariates are known and select
from them a random subset, acquiring the ground truth labels for each.
Sometimes these labels might be available data that has already been
collected (e.g., did a patient die within the following year?) and other
times we might need to employ human annotators to label the data, (e.g.,
assigning images to categories).</p>
<p>Together, these inputs and corresponding labels comprise the training
set. We feed the training dataset into a supervised learning algorithm,
a function that takes as input a dataset and outputs another function,
<em>the learned model</em>. Finally, we can feed previously unseen inputs to
the learned model, using its outputs as predictions of the corresponding
label. The full process in drawn in <a class="reference internal" href="#fig-supervised-learning"><span class="std std-numref">Fig. 1.3.1</span></a>.</p>
<div class="figure align-default" id="id43">
<span id="fig-supervised-learning"></span><img alt="../_images/supervised-learning.svg" src="../_images/supervised-learning.svg" /><p class="caption"><span class="caption-number">Fig. 1.3.1 </span><span class="caption-text">Supervised learning.</span><a class="headerlink" href="#id43" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="regression">
<h4><span class="section-number">1.3.1.1. </span>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">¶</a></h4>
<p>Perhaps the simplest supervised learning task to wrap your head around
is <em>regression</em>. Consider, for example a set of data harvested from a
database of home sales. We might construct a table, where each row
corresponds to a different house, and each column corresponds to some
relevant attribute, such as the square footage of a house, the number of
bedrooms, the number of bathrooms, and the number of minutes (walking)
to the center of town. In this dataset each <em>example</em> would be a
specific house, and the corresponding <em>feature vector</em> would be one row
in the table.</p>
<p>If you live in New York or San Francisco, and you are not the CEO of
Amazon, Google, Microsoft, or Facebook, the (sq. footage, no. of
bedrooms, no. of bathrooms, walking distance) feature vector for your
home might look something like: <span class="math notranslate nohighlight">\([100, 0, .5, 60]\)</span>. However, if
you live in Pittsburgh, it might look more like
<span class="math notranslate nohighlight">\([3000, 4, 3, 10]\)</span>. Feature vectors like this are essential for
most classic machine learning algorithms. We will continue to denote the
feature vector correspond to any example <span class="math notranslate nohighlight">\(i\)</span> as
<span class="math notranslate nohighlight">\(\mathbf{x}_i\)</span> and we can compactly refer to the full table
containing all of the feature vectors as <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>What makes a problem a <em>regression</em> is actually the outputs. Say that
you are in the market for a new home. You might want to estimate the
fair market value of a house, given some features like these. The target
value, the price of sale, is a <em>real number</em>. If you remember the formal
definition of the reals you might be scratching your head now. Homes
probably never sell for fractions of a cent, let alone prices expressed
as irrational numbers. In cases like this, when the target is actually
discrete, but where the rounding takes place on a sufficiently fine
scale, we will abuse language just a bit cn continue to describe our
outputs and targets as real-valued numbers.</p>
<p>We denote any individual target <span class="math notranslate nohighlight">\(y_i\)</span> (corresponding to example
<span class="math notranslate nohighlight">\(\mathbf{x_i}\)</span>) and the set of all targets <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>
(corresponding to all examples <span class="math notranslate nohighlight">\(X\)</span>). When our targets take on
arbitrary values in some range, we call this a regression problem. Our
goal is to produce a model whose predictions closely approximate the
actual target values. We denote the predicted target for any instance
<span class="math notranslate nohighlight">\(\hat{y}_i\)</span>. Do not worry if the notation is bogging you down. We
will unpack it more thoroughly in the subsequent chapters.</p>
<p>Lots of practical problems are well-described regression problems.
Predicting the rating that a user will assign to a movie can be thought
of as a regression problem and if you designed a great algorithm to
accomplish this feat in 2009, you might have won the <a class="reference external" href="https://en.wikipedia.org/wiki/Netflix_Prize">1-million-dollar
Netflix prize</a>.
Predicting the length of stay for patients in the hospital is also a
regression problem. A good rule of thumb is that any <em>How much?</em> or <em>How
many?</em> problem should suggest regression.</p>
<ul class="simple">
<li><p>“How many hours will this surgery take?”: <em>regression</em></p></li>
<li><p>“How many dogs are in this photo?”: <em>regression</em>.</p></li>
</ul>
<p>However, if you can easily pose your problem as “Is this a _ ?”, then
it is likely, classification, a different kind of supervised problem
that we will cover next. Even if you have never worked with machine
learning before, you have probably worked through a regression problem
informally. Imagine, for example, that you had your drains repaired and
that your contractor spent <span class="math notranslate nohighlight">\(x_1=3\)</span> hours removing gunk from your
sewage pipes. Then she sent you a bill of <span class="math notranslate nohighlight">\(y_1 = \$350\)</span>. Now
imagine that your friend hired the same contractor for <span class="math notranslate nohighlight">\(x_2 = 2\)</span>
hours and that she received a bill of <span class="math notranslate nohighlight">\(y_2 = \$250\)</span>. If someone
then asked you how much to expect on their upcoming gunk-removal invoice
you might make some reasonable assumptions, such as more hours worked
costs more dollars. You might also assume that there is some base charge
and that the contractor then charges per hour. If these assumptions held
true, then given these two data points, you could already identify the
contractor’s pricing structure: $100 per hour plus $50 to show up at
your house. If you followed that much then you already understand the
high-level idea behind linear regression (and you just implicitly
designed a linear model with a bias term).</p>
<p>In this case, we could produce the parameters that exactly matched the
contractor’s prices. Sometimes that is not possible, e.g., if some of
the variance owes to some factors besides your two features. In these
cases, we will try to learn models that minimize the distance between
our predictions and the observed values. In most of our chapters, we
will focus on one of two very common losses, the <a class="reference external" href="http://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.L1Loss">L1
loss</a>
where</p>
<div class="math notranslate nohighlight" id="equation-chapter-introduction-index-0">
<span class="eqno">(1.3.1)<a class="headerlink" href="#equation-chapter-introduction-index-0" title="Permalink to this equation">¶</a></span>\[l(y, y') = \sum_i |y_i-y_i'|\]</div>
<p>and the least mean squares loss, or <a class="reference external" href="http://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.L2Loss">L2
loss</a>,
where</p>
<div class="math notranslate nohighlight" id="equation-chapter-introduction-index-1">
<span class="eqno">(1.3.2)<a class="headerlink" href="#equation-chapter-introduction-index-1" title="Permalink to this equation">¶</a></span>\[l(y, y') = \sum_i (y_i - y_i')^2.\]</div>
<p>As we will see later, the <span class="math notranslate nohighlight">\(L_2\)</span> loss corresponds to the assumption
that our data was corrupted by Gaussian noise, whereas the <span class="math notranslate nohighlight">\(L_1\)</span>
loss corresponds to an assumption of noise from a Laplace distribution.</p>
</div>
<div class="section" id="id12">
<h4><span class="section-number">1.3.1.2. </span>التّصنيف<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h4>
<p>While regression models are great for addressing <em>how many?</em> questions,
lots of problems do not bend comfortably to this template. For example,
a bank wants to add check scanning to their mobile app. This would
involve the customer snapping a photo of a check with their smart
phone’s camera and the machine learning model would need to be able to
automatically understand text seen in the image. It would also need to
understand hand-written text to be even more robust. This kind of system
is referred to as optical character recognition (OCR), and the kind of
problem it addresses is called <em>classification</em>. It is treated with a
different set of algorithms than those used for regression (although
many techniques will carry over).</p>
<p>In classification, we want our model to look at a feature vector, e.g.,
the pixel values in an image, and then predict which category (formally
called <em>classes</em>), among some (discrete) set of options, an example
belongs. For hand-written digits, we might have 10 classes,
corresponding to the digits 0 through 9. The simplest form of
classification is when there are only two classes, a problem which we
call binary classification. For example, our dataset <span class="math notranslate nohighlight">\(X\)</span> could
consist of images of animals and our <em>labels</em> <span class="math notranslate nohighlight">\(Y\)</span> might be the
classes <span class="math notranslate nohighlight">\(\mathrm{\{cat, dog\}}\)</span>. While in regression, we sought a
<em>regressor</em> to output a real value <span class="math notranslate nohighlight">\(\hat{y}\)</span>, in classification,
we seek a <em>classifier</em>, whose output <span class="math notranslate nohighlight">\(\hat{y}\)</span> is the predicted
class assignment.</p>
<p>For reasons that we will get into as the book gets more technical, it
can be hard to optimize a model that can only output a hard categorical
assignment, e.g., either <em>cat</em> or <em>dog</em>. In these cases, it is usually
much easier to instead express our model in the language of
probabilities. Given an example <span class="math notranslate nohighlight">\(x\)</span>, our model assigns a
probability <span class="math notranslate nohighlight">\(\hat{y}_k\)</span> to each label <span class="math notranslate nohighlight">\(k\)</span>. Because these are
probabilities, they need to be positive numbers and add up to <span class="math notranslate nohighlight">\(1\)</span>
and thus we only need <span class="math notranslate nohighlight">\(K-1\)</span> numbers to assign probabilities of
<span class="math notranslate nohighlight">\(K\)</span> categories. This is easy to see for binary classification. If
there is a <span class="math notranslate nohighlight">\(0.6\)</span> (<span class="math notranslate nohighlight">\(60\%\)</span>) probability that an unfair coin
comes up heads, then there is a <span class="math notranslate nohighlight">\(0.4\)</span> (<span class="math notranslate nohighlight">\(40\%\)</span>) probability
that it comes up tails. Returning to our animal classification example,
a classifier might see an image and output the probability that the
image is a cat <span class="math notranslate nohighlight">\(P(y=\text{cat} \mid x) = 0.9\)</span>. We can interpret
this number by saying that the classifier is <span class="math notranslate nohighlight">\(90\%\)</span> sure that the
image depicts a cat. The magnitude of the probability for the predicted
class conveys one notion of uncertainty. It is not the only notion of
uncertainty and we will discuss others in more advanced chapters.</p>
<p>When we have more than two possible classes, we call the problem
<em>multiclass classification</em>. Common examples include hand-written
character recognition <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3</span> <span class="pre">...</span> <span class="pre">9,</span> <span class="pre">a,</span> <span class="pre">b,</span> <span class="pre">c,</span> <span class="pre">...]</span></code>. While we
attacked regression problems by trying to minimize the L1 or L2 loss
functions, the common loss function for classification problems is
called cross-entropy. In MXNet Gluon, the corresponding loss function
can be found
<a class="reference external" href="https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.SoftmaxCrossEntropyLoss">here</a>.</p>
<p>Note that the most likely class is not necessarily the one that you are
going to use for your decision. Assume that you find this beautiful
mushroom in your backyard as shown in <a class="reference internal" href="#fig-death-cap"><span class="std std-numref">Fig. 1.3.2</span></a>.</p>
<div class="figure align-default" id="id44">
<span id="fig-death-cap"></span><a class="reference internal image-reference" href="../_images/death_cap.jpg"><img alt="../_images/death_cap.jpg" src="../_images/death_cap.jpg" style="width: 200px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.3.2 </span><span class="caption-text">Death cap—do not eat!</span><a class="headerlink" href="#id44" title="Permalink to this image">¶</a></p>
</div>
<p>Now, assume that you built a classifier and trained it to predict if a
mushroom is poisonous based on a photograph. Say our poison-detection
classifier outputs <span class="math notranslate nohighlight">\(P(y=\mathrm{death cap}|\mathrm{image}) = 0.2\)</span>.
In other words, the classifier is <span class="math notranslate nohighlight">\(80\%\)</span> sure that our mushroom
<em>is not</em> a death cap. Still, you’d have to be a fool to eat it. That is
because the certain benefit of a delicious dinner is not worth a
<span class="math notranslate nohighlight">\(20\%\)</span> risk of dying from it. In other words, the effect of the
<em>uncertain risk</em> outweighs the benefit by far. We can look at this more
formally. Basically, we need to compute the expected risk that we incur,
i.e., we need to multiply the probability of the outcome with the
benefit (or harm) associated with it:</p>
<div class="math notranslate nohighlight" id="equation-chapter-introduction-index-2">
<span class="eqno">(1.3.3)<a class="headerlink" href="#equation-chapter-introduction-index-2" title="Permalink to this equation">¶</a></span>\[L(\mathrm{action}| x) = E_{y \sim p(y| x)}[\mathrm{loss}(\mathrm{action},y)].\]</div>
<p>Hence, the loss <span class="math notranslate nohighlight">\(L\)</span> incurred by eating the mushroom is
<span class="math notranslate nohighlight">\(L(a=\mathrm{eat}| x) = 0.2 * \infty + 0.8 * 0 = \infty\)</span>, whereas
the cost of discarding it is
<span class="math notranslate nohighlight">\(L(a=\mathrm{discard}| x) = 0.2 * 0 + 0.8 * 1 = 0.8\)</span>.</p>
<p>Our caution was justified: as any mycologist would tell us, the above
mushroom actually <em>is</em> a death cap. Classification can get much more
complicated than just binary, multiclass, or even multi-label
classification. For instance, there are some variants of classification
for addressing hierarchies. Hierarchies assume that there exist some
relationships among the many classes. So not all errors are equal—if we
must err, we would prefer to misclassify to a related class rather than
to a distant class. Usually, this is referred to as <em>hierarchical
classification</em>. One early example is due to
<a class="reference external" href="https://en.wikipedia.org/wiki/Carl_Linnaeus">Linnaeus</a>, who
organized the animals in a hierarchy.</p>
<p>In the case of animal classification, it might not be so bad to mistake
a poodle for a schnauzer, but our model would pay a huge penalty if it
confused a poodle for a dinosaur. Which hierarchy is relevant might
depend on how you plan to use the model. For example, rattle snakes and
garter snakes might be close on the phylogenetic tree, but mistaking a
rattler for a garter could be deadly.</p>
</div>
<div class="section" id="tagging">
<h4><span class="section-number">1.3.1.3. </span>Tagging<a class="headerlink" href="#tagging" title="Permalink to this headline">¶</a></h4>
<p>Some classification problems do not fit neatly into the binary or
multiclass classification setups. For example, we could train a normal
binary classifier to distinguish cats from dogs. Given the current state
of computer vision, we can do this easily, with off-the-shelf tools.
Nonetheless, no matter how accurate our model gets, we might find
ourselves in trouble when the classifier encounters an image of the Town
Musicians of Bremen.</p>
<div class="figure align-default" id="id45">
<span id="subsec-recommender-systems"></span><a class="reference internal image-reference" href="../_images/stackedanimals.jpg"><img alt="../_images/stackedanimals.jpg" src="../_images/stackedanimals.jpg" style="width: 300px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.3.3 </span><span class="caption-text">A cat, a roster, a dog and a donkey</span><a class="headerlink" href="#id45" title="Permalink to this image">¶</a></p>
</div>
<p>As you can see, there is a cat in the picture, and a rooster, a dog, a
donkey and a bird, with some trees in the background. Depending on what
we want to do with our model ultimately, treating this as a binary
classification problem might not make a lot of sense. Instead, we might
want to give the model the option of saying the image depicts a cat
<em>and</em> a dog <em>and</em> a donkey <em>and</em> a rooster <em>and</em> a bird.</p>
<p>The problem of learning to predict classes that are <em>not mutually
exclusive</em> is called multi-label classification. Auto-tagging problems
are typically best described as multi-label classification problems.
Think of the tags people might apply to posts on a tech blog, e.g.,
“machine learning”, “technology”, “gadgets”, “programming languages”,
“linux”, “cloud computing”, “AWS”. A typical article might have 5-10
tags applied because these concepts are correlated. Posts about “cloud
computing” are likely to mention “AWS” and posts about “machine
learning” could also deal with “programming languages”.</p>
<p>We also have to deal with this kind of problem when dealing with the
biomedical literature, where correctly tagging articles is important
because it allows researchers to do exhaustive reviews of the
literature. At the National Library of Medicine, a number of
professional annotators go over each article that gets indexed in PubMed
to associate it with the relevant terms from MeSH, a collection of
roughly 28k tags. This is a time-consuming process and the annotators
typically have a one year lag between archiving and tagging. Machine
learning can be used here to provide provisional tags until each article
can have a proper manual review. Indeed, for several years, the BioASQ
organization has <a class="reference external" href="http://bioasq.org/">hosted a competition</a> to do
precisely this.</p>
</div>
<div class="section" id="search-and-ranking">
<h4><span class="section-number">1.3.1.4. </span>Search and ranking<a class="headerlink" href="#search-and-ranking" title="Permalink to this headline">¶</a></h4>
<p>Sometimes we do not just want to assign each example to a bucket or to a
real value. In the field of information retrieval, we want to impose a
ranking on a set of items. Take web search for example, the goal is less
to determine whether a particular page is relevant for a query, but
rather, which one of the plethora of search results is <em>most relevant</em>
for a particular user. We really care about the ordering of the relevant
search results and our learning algorithm needs to produce ordered
subsets of elements from a larger set. In other words, if we are asked
to produce the first 5 letters from the alphabet, there is a difference
between returning <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">B</span> <span class="pre">C</span> <span class="pre">D</span> <span class="pre">E</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">A</span> <span class="pre">B</span> <span class="pre">E</span> <span class="pre">D</span></code>. Even if the result
set is the same, the ordering within the set matters.</p>
<p>One possible solution to this problem is to first assign to every
element in the set a corresponding relevance score and then to retrieve
the top-rated elements.
<a class="reference external" href="https://en.wikipedia.org/wiki/PageRank">PageRank</a>, the original
secret sauce behind the Google search engine was an early example of
such a scoring system but it was peculiar in that it did not depend on
the actual query. Here they relied on a simple relevance filter to
identify the set of relevant items and then on PageRank to order those
results that contained the query term. Nowadays, search engines use
machine learning and behavioral models to obtain query-dependent
relevance scores. There are entire academic conferences devoted to this
subject.</p>
</div>
<div class="section" id="recommender-systems">
<h4><span class="section-number">1.3.1.5. </span>Recommender systems<a class="headerlink" href="#recommender-systems" title="Permalink to this headline">¶</a></h4>
<p>Recommender systems are another problem setting that is related to
search and ranking. The problems are similar insofar as the goal is to
display a set of relevant items to the user. The main difference is the
emphasis on <em>personalization</em> to specific users in the context of
recommender systems. For instance, for movie recommendations, the
results page for a SciFi fan and the results page for a connoisseur of
Peter Sellers comedies might differ significantly. Similar problems pop
up in other recommendation settings, e.g., for retail products, music,
or news recommendation.</p>
<p>In some cases, customers provide explicit feedback communicating how
much they liked a particular product (e.g., the product ratings and
reviews on Amazon, IMDB, GoodReads, etc.). In some other cases, they
provide implicit feedback, e.g., by skipping titles on a playlist, which
might indicate dissatisfaction but might just indicate that the song was
inappropriate in context. In the simplest formulations, these systems
are trained to estimate some score <span class="math notranslate nohighlight">\(y_{ij}\)</span>, such as an estimated
rating or the probability of purchase, given a user <span class="math notranslate nohighlight">\(u_i\)</span> and
product <span class="math notranslate nohighlight">\(p_j\)</span>.</p>
<p>Given such a model, then for any given user, we could retrieve the set
of objects with the largest scores <span class="math notranslate nohighlight">\(y_{ij}\)</span>, which are could then
be recommended to the customer. Production systems are considerably more
advanced and take detailed user activity and item characteristics into
account when computing such scores. <a class="reference internal" href="#fig-deeplearning-amazon"><span class="std std-numref">Fig. 1.3.4</span></a>
is an example of deep learning books recommended by Amazon based on
personalization algorithms tuned to capture the author’s preferences.</p>
<div class="figure align-default" id="id46">
<span id="fig-deeplearning-amazon"></span><img alt="../_images/deeplearning_amazon.png" src="../_images/deeplearning_amazon.png" />
<p class="caption"><span class="caption-number">Fig. 1.3.4 </span><span class="caption-text">Deep learning books recommended by Amazon.</span><a class="headerlink" href="#id46" title="Permalink to this image">¶</a></p>
</div>
<p>Despite their tremendous economic value, recommendation systems naively
built on top of predictive models suffer some serious conceptual flaws.
To start, we only observe <em>censored feedback</em>. Users preferentially rate
movies that they feel strongly about: you might notice that items
receive many 5 and 1 star ratings but that there are conspicuously few
3-star ratings. Moreover, current purchase habits are often a result of
the recommendation algorithm currently in place, but learning algorithms
do not always take this detail into account. Thus it is possible for
feedback loops to form where a recommender system preferentially pushes
an item that is then taken to be better (due to greater purchases) and
in turn is recommended even more frequently. Many of these problems
about how to deal with censoring, incentives, and feedback loops, are
important open research questions.</p>
</div>
<div class="section" id="sequence-learning">
<h4><span class="section-number">1.3.1.6. </span>Sequence Learning<a class="headerlink" href="#sequence-learning" title="Permalink to this headline">¶</a></h4>
<p>So far, we have looked at problems where we have some fixed number of
inputs and produce a fixed number of outputs. Before we considered
predicting home prices from a fixed set of features: square footage,
number of bedrooms, number of bathrooms, walking time to downtown. We
also discussed mapping from an image (of fixed dimension) to the
predicted probabilities that it belongs to each of a fixed number of
classes, or taking a user ID and a product ID, and predicting a star
rating. In these cases, once we feed our fixed-length input into the
model to generate an output, the model immediately forgets what it just
saw.</p>
<p>This might be fine if our inputs truly all have the same dimensions and
if successive inputs truly have nothing to do with each other. But how
would we deal with video snippets? In this case, each snippet might
consist of a different number of frames. And our guess of what is going
on in each frame might be much stronger if we take into account the
previous or succeeding frames. Same goes for language. One popular deep
learning problem is machine translation: the task of ingesting sentences
in some source language and predicting their translation in another
language.</p>
<p>These problems also occur in medicine. We might want a model to monitor
patients in the intensive care unit and to fire off alerts if their risk
of death in the next 24 hours exceeds some threshold. We definitely
would not want this model to throw away everything it knows about the
patient history each hour and just make its predictions based on the
most recent measurements.</p>
<p>These problems are among the most exciting applications of machine
learning and they are instances of <em>sequence learning</em>. They require a
model to either ingest sequences of inputs or to emit sequences of
outputs (or both!). These latter problems are sometimes referred to as
<code class="docutils literal notranslate"><span class="pre">seq2seq</span></code> problems. Language translation is a <code class="docutils literal notranslate"><span class="pre">seq2seq</span></code> problem.
Transcribing text from spoken speech is also a <code class="docutils literal notranslate"><span class="pre">seq2seq</span></code> problem.
While it is impossible to consider all types of sequence
transformations, a number of special cases are worth mentioning:</p>
<p><strong>Tagging and Parsing</strong>. This involves annotating a text sequence with
attributes. In other words, the number of inputs and outputs is
essentially the same. For instance, we might want to know where the
verbs and subjects are. Alternatively, we might want to know which words
are the named entities. In general, the goal is to decompose and
annotate text based on structural and grammatical assumptions to get
some annotation. This sounds more complex than it actually is. Below is
a very simple example of annotating a sentence with tags indicating
which words refer to named entities.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Tom has dinner in Washington with Sally.
Ent  -    -    -     Ent      -    Ent
</pre></div>
</div>
<p><strong>Automatic Speech Recognition</strong>. With speech recognition, the input
sequence <span class="math notranslate nohighlight">\(x\)</span> is an audio recording of a speaker (shown in
<a class="reference internal" href="#fig-speech"><span class="std std-numref">Fig. 1.3.5</span></a>), and the output <span class="math notranslate nohighlight">\(y\)</span> is the textual
transcript of what the speaker said. The challenge is that there are
many more audio frames (sound is typically sampled at 8kHz or 16kHz)
than text, i.e., there is no 1:1 correspondence between audio and text,
since thousands of samples correspond to a single spoken word. These are
<code class="docutils literal notranslate"><span class="pre">seq2seq</span></code> problems where the output is much shorter than the input.</p>
<div class="figure align-default" id="id47">
<span id="fig-speech"></span><a class="reference internal image-reference" href="../_images/speech.png"><img alt="../_images/speech.png" src="../_images/speech.png" style="width: 700px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.3.5 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">-D-e-e-p-</span> <span class="pre">L-ea-r-ni-ng-</span></code></span><a class="headerlink" href="#id47" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Text to Speech</strong>. Text-to-Speech (TTS) is the inverse of speech
recognition. In other words, the input <span class="math notranslate nohighlight">\(x\)</span> is text and the output
<span class="math notranslate nohighlight">\(y\)</span> is an audio file. In this case, the output is <em>much longer</em>
than the input. While it is easy for <em>humans</em> to recognize a bad audio
file, this is not quite so trivial for computers.</p>
<p><strong>Machine Translation</strong>. Unlike the case of speech recognition, where
corresponding inputs and outputs occur in the same order (after
alignment), in machine translation, order inversion can be vital. In
other words, while we are still converting one sequence into another,
neither the number of inputs and outputs nor the order of corresponding
data points are assumed to be the same. Consider the following
illustrative example of the peculiar tendency of Germans to place the
verbs at the end of sentences.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>German:           Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?
English:          Did you already check out this excellent tutorial?
Wrong alignment:  Did you yourself already this excellent tutorial looked-at?
</pre></div>
</div>
<p>Many related problems pop up in other learning tasks. For instance,
determining the order in which a user reads a Webpage is a
two-dimensional layout analysis problem. Dialogue problems exhibit all
kinds of additional complications, where determining what to say next
requires taking into account real-world knowledge and the prior state of
the conversation across long temporal distances. This is an active area
of research.</p>
</div>
</div>
<div class="section" id="unsupervised-learning">
<h3><span class="section-number">1.3.2. </span>Unsupervised learning<a class="headerlink" href="#unsupervised-learning" title="Permalink to this headline">¶</a></h3>
<p>All the examples so far were related to <em>Supervised Learning</em>, i.e.,
situations where we feed the model a giant dataset containing both the
features and corresponding target values. You could think of the
supervised learner as having an extremely specialized job and an
extremely anal boss. The boss stands over your shoulder and tells you
exactly what to do in every situation until you learn to map from
situations to actions. Working for such a boss sounds pretty lame. On
the other hand, it is easy to please this boss. You just recognize the
pattern as quickly as possible and imitate their actions.</p>
<p>In a completely opposite way, it could be frustrating to work for a boss
who has no idea what they want you to do. However, if you plan to be a
data scientist, you’d better get used to it. The boss might just hand
you a giant dump of data and tell you to <em>do some data science with it!</em>
This sounds vague because it is. We call this class of problems
<em>unsupervised learning</em>, and the type and number of questions we could
ask is limited only by our creativity. We will address a number of
unsupervised learning techniques in later chapters. To whet your
appetite for now, we describe a few of the questions you might ask:</p>
<ul class="simple">
<li><p>Can we find a small number of prototypes that accurately summarize
the data? Given a set of photos, can we group them into landscape
photos, pictures of dogs, babies, cats, mountain peaks, etc.?
Likewise, given a collection of users’ browsing activity, can we
group them into users with similar behavior? This problem is
typically known as <em>clustering</em>.</p></li>
<li><p>Can we find a small number of parameters that accurately capture the
relevant properties of the data? The trajectories of a ball are quite
well described by velocity, diameter, and mass of the ball. Tailors
have developed a small number of parameters that describe human body
shape fairly accurately for the purpose of fitting clothes. These
problems are referred to as <em>subspace estimation</em> problems. If the
dependence is linear, it is called <em>principal component analysis</em>.</p></li>
<li><p>Is there a representation of (arbitrarily structured) objects in
Euclidean space (i.e., the space of vectors in <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>)
such that symbolic properties can be well matched? This is called
<em>representation learning</em> and it is used to describe entities and
their relations, such as Rome <span class="math notranslate nohighlight">\(-\)</span> Italy <span class="math notranslate nohighlight">\(+\)</span> France
<span class="math notranslate nohighlight">\(=\)</span> Paris.</p></li>
<li><p>Is there a description of the root causes of much of the data that we
observe? For instance, if we have demographic data about house
prices, pollution, crime, location, education, salaries, etc., can we
discover how they are related simply based on empirical data? The
fields concerned with <em>causality</em> and <em>probabilistic graphical
models</em> address this problem.</p></li>
<li><p>Another important and exciting recent development in unsupervised
learning is the advent of <em>generative adversarial networks</em>. These
give us a procedural way to synthesize data, even complicated
structured data like images and audio. The underlying statistical
mechanisms are tests to check whether real and fake data are the
same. We will devote a few notebooks to them.</p></li>
</ul>
</div>
<div class="section" id="interacting-with-an-environment">
<h3><span class="section-number">1.3.3. </span>Interacting with an Environment<a class="headerlink" href="#interacting-with-an-environment" title="Permalink to this headline">¶</a></h3>
<p>So far, we have not discussed where data actually comes from, or what
actually <em>happens</em> when a machine learning model generates an output.
That is because supervised learning and unsupervised learning do not
address these issues in a very sophisticated way. In either case, we
grab a big pile of data up front, then set our pattern recognition
machines in motion without ever interacting with the environment again.
Because all of the learning takes place after the algorithm is
disconnected from the environment, this is sometimes called <em>offline
learning</em>. For supervised learning, the process looks like
<a class="reference internal" href="#fig-data-collection"><span class="std std-numref">Fig. 1.3.6</span></a>.</p>
<div class="figure align-default" id="id48">
<span id="fig-data-collection"></span><img alt="../_images/data-collection.svg" src="../_images/data-collection.svg" /><p class="caption"><span class="caption-number">Fig. 1.3.6 </span><span class="caption-text">Collect data for supervised learning from an environment.</span><a class="headerlink" href="#id48" title="Permalink to this image">¶</a></p>
</div>
<p>This simplicity of offline learning has its charms. The upside is we can
worry about pattern recognition in isolation, without any distraction
from these other problems. But the downside is that the problem
formulation is quite limiting. If you are more ambitious, or if you grew
up reading Asimov’s Robot Series, then you might imagine artificially
intelligent bots capable not only of making predictions, but of taking
actions in the world. We want to think about intelligent <em>agents</em>, not
just predictive <em>models</em>. That means we need to think about choosing
<em>actions</em>, not just making <em>predictions</em>. Moreover, unlike predictions,
actions actually impact the environment. If we want to train an
intelligent agent, we must account for the way its actions might impact
the future observations of the agent.</p>
<p>Considering the interaction with an environment opens a whole set of new
modeling questions. Does the environment:</p>
<ul class="simple">
<li><p>Remember what we did previously?</p></li>
<li><p>Want to help us, e.g., a user reading text into a speech recognizer?</p></li>
<li><p>Want to beat us, i.e., an adversarial setting like spam filtering
(against spammers) or playing a game (vs an opponent)?</p></li>
<li><p>Not care (as in many cases)?</p></li>
<li><p>Have shifting dynamics (does future data always resemble the past or
do the patterns change over time, either naturally or in response to
our automated tools)?</p></li>
</ul>
<p>This last question raises the problem of <em>distribution shift</em>, (when
training and test data are different). It is a problem that most of us
have experienced when taking exams written by a lecturer, while the
homeworks were composed by her TAs. We will briefly describe
reinforcement learning and adversarial learning, two settings that
explicitly consider interaction with an environment.</p>
</div>
<div class="section" id="reinforcement-learning">
<h3><span class="section-number">1.3.4. </span>Reinforcement learning<a class="headerlink" href="#reinforcement-learning" title="Permalink to this headline">¶</a></h3>
<p>If you are interested in using machine learning to develop an agent that
interacts with an environment and takes actions, then you are probably
going to wind up focusing on <em>reinforcement learning</em> (RL). This might
include applications to robotics, to dialogue systems, and even to
developing AI for video games. <em>Deep reinforcement learning</em> (DRL),
which applies deep neural networks to RL problems, has surged in
popularity. The breakthrough <a class="reference external" href="https://www.wired.com/2015/02/google-ai-plays-atari-like-pros/">deep Q-network that beat humans at Atari
games using only the visual
input</a>,
and the <a class="reference external" href="https://www.wired.com/2017/05/googles-alphago-trounces-humans-also-gives-boost/">AlphaGo program that dethroned the world champion at the board
game
Go</a>
are two prominent examples.</p>
<p>Reinforcement learning gives a very general statement of a problem, in
which an agent interacts with an environment over a series of
<em>timesteps</em>. At each timestep <span class="math notranslate nohighlight">\(t\)</span>, the agent receives some
observation <span class="math notranslate nohighlight">\(o_t\)</span> from the environment and must choose an action
<span class="math notranslate nohighlight">\(a_t\)</span> that is subsequently transmitted back to the environment via
some mechanism (sometimes called an actuator). Finally, the agent
receives a reward <span class="math notranslate nohighlight">\(r_t\)</span> from the environment. The agent then
receives a subsequent observation, and chooses a subsequent action, and
so on. The behavior of an RL agent is governed by a <em>policy</em>. In short,
a <em>policy</em> is just a function that maps from observations (of the
environment) to actions. The goal of reinforcement learning is to
produce a good policy.</p>
<div class="figure align-default" id="id49">
<img alt="../_images/rl-environment.svg" src="../_images/rl-environment.svg" /><p class="caption"><span class="caption-number">Fig. 1.3.7 </span><span class="caption-text">The interaction between reinforcement learning and an environment.</span><a class="headerlink" href="#id49" title="Permalink to this image">¶</a></p>
</div>
<p>It is hard to overstate the generality of the RL framework. For example,
we can cast any supervised learning problem as an RL problem. Say we had
a classification problem. We could create an RL agent with one <em>action</em>
corresponding to each class. We could then create an environment which
gave a reward that was exactly equal to the loss function from the
original supervised problem.</p>
<p>That being said, RL can also address many problems that supervised
learning cannot. For example, in supervised learning we always expect
that the training input comes associated with the correct label. But in
RL, we do not assume that for each observation, the environment tells us
the optimal action. In general, we just get some reward. Moreover, the
environment may not even tell us which actions led to the reward.</p>
<p>Consider for example the game of chess. The only real reward signal
comes at the end of the game when we either win, which we might assign a
reward of 1, or when we lose, which we could assign a reward of -1. So
reinforcement learners must deal with the <em>credit assignment problem</em>:
determining which actions to credit or blame for an outcome. The same
goes for an employee who gets a promotion on October 11. That promotion
likely reflects a large number of well-chosen actions over the previous
year. Getting more promotions in the future requires figuring out what
actions along the way led to the promotion.</p>
<p>Reinforcement learners may also have to deal with the problem of partial
observability. That is, the current observation might not tell you
everything about your current state. Say a cleaning robot found itself
trapped in one of many identical closets in a house. Inferring the
precise location (and thus state) of the robot might require considering
its previous observations before entering the closet.</p>
<p>Finally, at any given point, reinforcement learners might know of one
good policy, but there might be many other better policies that the
agent has never tried. The reinforcement learner must constantly choose
whether to <em>exploit</em> the best currently-known strategy as a policy, or
to <em>explore</em> the space of strategies, potentially giving up some
short-run reward in exchange for knowledge.</p>
<div class="section" id="mdps-bandits-and-friends">
<h4><span class="section-number">1.3.4.1. </span>MDPs, bandits, and friends<a class="headerlink" href="#mdps-bandits-and-friends" title="Permalink to this headline">¶</a></h4>
<p>The general reinforcement learning problem is a very general setting.
Actions affect subsequent observations. Rewards are only observed
corresponding to the chosen actions. The environment may be either fully
or partially observed. Accounting for all this complexity at once may
ask too much of researchers. Moreover, not every practical problem
exhibits all this complexity. As a result, researchers have studied a
number of <em>special cases</em> of reinforcement learning problems.</p>
<p>When the environment is fully observed, we call the RL problem a <em>Markov
Decision Process</em> (MDP). When the state does not depend on the previous
actions, we call the problem a <em>contextual bandit problem</em>. When there
is no state, just a set of available actions with initially unknown
rewards, this problem is the classic <em>multi-armed bandit problem</em>.</p>
</div>
</div>
</div>
<div class="section" id="roots">
<h2><span class="section-number">1.4. </span>Roots<a class="headerlink" href="#roots" title="Permalink to this headline">¶</a></h2>
<p>Although many deep learning methods are recent inventions, humans have
held the desire to analyze data and to predict future outcomes for
centuries. In fact, much of natural science has its roots in this. For
instance, the Bernoulli distribution is named after <a class="reference external" href="https://en.wikipedia.org/wiki/Jacob_Bernoulli">Jacob Bernoulli
(1655-1705)</a>, and the
Gaussian distribution was discovered by <a class="reference external" href="https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss">Carl Friedrich Gauss
(1777-1855)</a>. He
invented for instance the least mean squares algorithm, which is still
used today for countless problems from insurance calculations to medical
diagnostics. These tools gave rise to an experimental approach in the
natural sciences—for instance, Ohm’s law relating current and voltage in
a resistor is perfectly described by a linear model.</p>
<p>Even in the middle ages, mathematicians had a keen intuition of
estimates. For instance, the geometry book of <a class="reference external" href="https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry">Jacob Köbel
(1460-1533)</a>
illustrates averaging the length of 16 adult men’s feet to obtain the
average foot length.</p>
<div class="figure align-default" id="id50">
<span id="fig-koebel"></span><a class="reference internal image-reference" href="../_images/koebel.jpg"><img alt="../_images/koebel.jpg" src="../_images/koebel.jpg" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Fig. 1.4.1 </span><span class="caption-text">Estimating the length of a foot</span><a class="headerlink" href="#id50" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#fig-koebel"><span class="std std-numref">Fig. 1.4.1</span></a> illustrates how this estimator works. The 16
adult men were asked to line up in a row, when leaving church. Their
aggregate length was then divided by 16 to obtain an estimate for what
now amounts to 1 foot. This “algorithm” was later improved to deal with
misshapen feet—the 2 men with the shortest and longest feet respectively
were sent away, averaging only over the remainder. This is one of the
earliest examples of the trimmed mean estimate.</p>
<p>Statistics really took off with the collection and availability of data.
One of its titans, <a class="reference external" href="https://en.wikipedia.org/wiki/Ronald_Fisher">Ronald Fisher
(1890-1962)</a>,
contributed significantly to its theory and also its applications in
genetics. Many of his algorithms (such as Linear Discriminant Analysis)
and formula (such as the Fisher Information Matrix) are still in
frequent use today (even the Iris dataset that he released in 1936 is
still used sometimes to illustrate machine learning algorithms). Fisher
was also a proponent of eugenics, which should remind us that the
morally dubious use data science has as long and enduring a history as
its productive use in industry and the natural sciences.</p>
<p>A second influence for machine learning came from Information Theory
<a class="reference external" href="https://en.wikipedia.org/wiki/Claude_Shannon">(Claude Shannon,
1916-2001)</a> and the
Theory of computation via <a class="reference external" href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing
(1912-1954)</a>. Turing posed
the question “can machines think?” in his famous paper <a class="reference external" href="https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence">Computing
machinery and
intelligence</a>
(Mind, October 1950). In what he described as the Turing test, a machine
can be considered intelligent if it is difficult for a human evaluator
to distinguish between the replies from a machine and a human based on
textual interactions.</p>
<p>Another influence can be found in neuroscience and psychology. After
all, humans clearly exhibit intelligent behavior. It is thus only
reasonable to ask whether one could explain and possibly reverse
engineer this capacity. One of the oldest algorithms inspired in this
fashion was formulated by <a class="reference external" href="https://en.wikipedia.org/wiki/Donald_O._Hebb">Donald Hebb
(1904-1985)</a>. In his
groundbreaking book The Organization of Behavior
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#hebb-hebb-1949" id="id13">[Hebb &amp; Hebb, 1949]</a>, he posited that neurons learn by positive
reinforcement. This became known as the Hebbian learning rule. It is the
prototype of Rosenblatt’s perceptron learning algorithm and it laid the
foundations of many stochastic gradient descent algorithms that underpin
deep learning today: reinforce desirable behavior and diminish
undesirable behavior to obtain good settings of the parameters in a
neural network.</p>
<p>Biological inspiration is what gave <em>neural networks</em> their name. For
over a century (dating back to the models of Alexander Bain, 1873 and
James Sherrington, 1890), researchers have tried to assemble
computational circuits that resemble networks of interacting neurons.
Over time, the interpretation of biology has become less literal but the
name stuck. At its heart, lie a few key principles that can be found in
most networks today:</p>
<ul class="simple">
<li><p>The alternation of linear and nonlinear processing units, often
referred to as <em>layers</em>.</p></li>
<li><p>The use of the chain rule (also known as <em>backpropagation</em>) for
adjusting parameters in the entire network at once.</p></li>
</ul>
<p>After initial rapid progress, research in neural networks languished
from around 1995 until 2005. This was due to a number of reasons.
Training a network is computationally very expensive. While RAM was
plentiful at the end of the past century, computational power was
scarce. Second, datasets were relatively small. In fact, Fisher’s Iris
dataset from 1932 was a popular tool for testing the efficacy of
algorithms. MNIST with its 60,000 handwritten digits was considered
huge.</p>
<p>Given the scarcity of data and computation, strong statistical tools
such as Kernel Methods, Decision Trees and Graphical Models proved
empirically superior. Unlike neural networks, they did not require weeks
to train and provided predictable results with strong theoretical
guarantees.</p>
</div>
<div class="section" id="id14">
<h2><span class="section-number">1.5. </span>الطريق إلى التعلم العميق<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>Much of this changed with the ready availability of large amounts of
data, due to the World Wide Web, the advent of companies serving
hundreds of millions of users online, a dissemination of cheap, high
quality sensors, cheap data storage (Kryder’s law), and cheap
computation (Moore’s law), in particular in the form of GPUs, originally
engineered for computer gaming. Suddenly algorithms and models that
seemed computationally infeasible became relevant (and vice versa). This
is best illustrated in <a class="reference internal" href="#tab-intro-decade"><span class="std std-numref">Table 1.5.1</span></a>.</p>
<span id="tab-intro-decade"></span><table class="docutils align-default" id="id51">
<caption><span class="caption-number">Table 1.5.1 </span><span class="caption-text">Dataset versus computer memory and computational power</span><a class="headerlink" href="#id51" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Decade</p></th>
<th class="head"><p>Dataset</p></th>
<th class="head"><p>Memory</p></th>
<th class="head"><p>Floating Point
Calculations
per Second</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1970</p></td>
<td><p>100 (Iris)</p></td>
<td><p>1 KB</p></td>
<td><p>100 KF (Intel
8080)</p></td>
</tr>
<tr class="row-odd"><td><p>1980</p></td>
<td><p>1 K (House
prices in
Boston)</p></td>
<td><p>100 KB</p></td>
<td><p>1 MF (Intel
80186)</p></td>
</tr>
<tr class="row-even"><td><p>1990</p></td>
<td><p>10 K (optical
character
recognition)</p></td>
<td><p>10 MB</p></td>
<td><p>10 MF (Intel
80486)</p></td>
</tr>
<tr class="row-odd"><td><p>2000</p></td>
<td><p>10 M (web
pages)</p></td>
<td><p>100 MB</p></td>
<td><p>1 GF (Intel
Core)</p></td>
</tr>
<tr class="row-even"><td><p>2010</p></td>
<td><p>10 G
(advertising)</p></td>
<td><p>1 GB</p></td>
<td><p>1 TF (Nvidia
C2050)</p></td>
</tr>
<tr class="row-odd"><td><p>2020</p></td>
<td><p>1 T (social
network)</p></td>
<td><p>100 GB</p></td>
<td><p>1 PF (Nvidia
DGX-2)</p></td>
</tr>
</tbody>
</table>
<p>It is evident that RAM has not kept pace with the growth in data. At the
same time, the increase in computational power has outpaced that of the
data available. This means that statistical models needed to become more
memory efficient (this is typically achieved by adding nonlinearities)
while simultaneously being able to spend more time on optimizing these
parameters, due to an increased compute budget. Consequently the sweet
spot in machine learning and statistics moved from (generalized) linear
models and kernel methods to deep networks. This is also one of the
reasons why many of the mainstays of deep learning, such as multilayer
perceptrons <a class="bibtex reference internal" href="../chapter_references/zreferences.html#mcculloch-pitts-1943" id="id15">[McCulloch &amp; Pitts, 1943]</a>, convolutional neural
networks <a class="bibtex reference internal" href="../chapter_references/zreferences.html#lecun-bottou-bengio-ea-1998" id="id16">[LeCun et al., 1998]</a>, Long Short-Term Memory
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#hochreiter-schmidhuber-1997" id="id17">[Hochreiter &amp; Schmidhuber, 1997]</a>, and Q-Learning
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#watkins-dayan-1992" id="id18">[Watkins &amp; Dayan, 1992]</a>, were essentially “rediscovered” in the
past decade, after laying comparatively dormant for considerable time.</p>
<p>The recent progress in statistical models, applications, and algorithms,
has sometimes been likened to the Cambrian Explosion: a moment of rapid
progress in the evolution of species. Indeed, the state of the art is
not just a mere consequence of available resources, applied to decades
old algorithms. Note that the list below barely scratches the surface of
the ideas that have helped researchers achieve tremendous progress over
the past decade.</p>
<ul class="simple">
<li><p>Novel methods for capacity control, such as Dropout
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#srivastava-hinton-krizhevsky-ea-2014" id="id19">[Srivastava et al., 2014]</a> have helped to
mitigate the danger of overfitting. This was achieved by applying
noise injection <a class="bibtex reference internal" href="../chapter_references/zreferences.html#bishop-1995" id="id20">[Bishop, 1995]</a> throughout the network,
replacing weights by random variables for training purposes.</p></li>
<li><p>Attention mechanisms solved a second problem that had plagued
statistics for over a century: how to increase the memory and
complexity of a system without increasing the number of learnable
parameters. <a class="bibtex reference internal" href="../chapter_references/zreferences.html#bahdanau-cho-bengio-2014" id="id21">[Bahdanau et al., 2014]</a> found an elegant
solution by using what can only be viewed as a learnable pointer
structure. Rather than having to remember an entire sentence, e.g.,
for machine translation in a fixed-dimensional representation, all
that needed to be stored was a pointer to the intermediate state of
the translation process. This allowed for significantly increased
accuracy for long sentences, since the model no longer needed to
remember the entire sentence before commencing the generation of a
new sentence.</p></li>
<li><p>Multi-stage designs, e.g., via the Memory Networks (MemNets)
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#sukhbaatar-weston-fergus-ea-2015" id="id22">[Sukhbaatar et al., 2015]</a> and the Neural
Programmer-Interpreter <a class="bibtex reference internal" href="../chapter_references/zreferences.html#reed-de-freitas-2015" id="id23">[Reed &amp; DeFreitas, 2015]</a> allowed
statistical modelers to describe iterative approaches to reasoning.
These tools allow for an internal state of the deep network to be
modified repeatedly, thus carrying out subsequent steps in a chain of
reasoning, similar to how a processor can modify memory for a
computation.</p></li>
<li><p>Another key development was the invention of GANS
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#goodfellow-pouget-abadie-mirza-ea-2014" id="id24">[Goodfellow et al., 2014]</a>. Traditionally,
statistical methods for density estimation and generative models
focused on finding proper probability distributions and (often
approximate) algorithms for sampling from them. As a result, these
algorithms were largely limited by the lack of flexibility inherent
in the statistical models. The crucial innovation in GANs was to
replace the sampler by an arbitrary algorithm with differentiable
parameters. These are then adjusted in such a way that the
discriminator (effectively a two-sample test) cannot distinguish fake
from real data. Through the ability to use arbitrary algorithms to
generate data, it opened up density estimation to a wide variety of
techniques. Examples of galloping Zebras
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#zhu-park-isola-ea-2017" id="id25">[Zhu et al., 2017]</a> and of fake celebrity faces
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#karras-aila-laine-ea-2017" id="id26">[Karras et al., 2017]</a> are both testimony to this
progress.</p></li>
<li><p>In many cases, a single GPU is insufficient to process the large
amounts of data available for training. Over the past decade the
ability to build parallel distributed training algorithms has
improved significantly. One of the key challenges in designing
scalable algorithms is that the workhorse of deep learning
optimization, stochastic gradient descent, relies on relatively small
minibatches of data to be processed. At the same time, small batches
limit the efficiency of GPUs. Hence, training on 1024 GPUs with a
minibatch size of, say 32 images per batch amounts to an aggregate
minibatch of 32k images. Recent work, first by Li <a class="bibtex reference internal" href="../chapter_references/zreferences.html#li-2017" id="id27">[Li, 2017]</a>,
and subsequently by <a class="bibtex reference internal" href="../chapter_references/zreferences.html#you-gitman-ginsburg-2017" id="id28">[You et al., 2017]</a> and
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#jia-song-he-ea-2018" id="id29">[Jia et al., 2018]</a> pushed the size up to 64k observations,
reducing training time for ResNet50 on ImageNet to less than 7
minutes. For comparison—initially training times were measured in the
order of days.</p></li>
<li><p>The ability to parallelize computation has also contributed quite
crucially to progress in reinforcement learning, at least whenever
simulation is an option. This has led to significant progress in
computers achieving superhuman performance in Go, Atari games,
Starcraft, and in physics simulations (e.g., using MuJoCo). See e.g.,
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#silver-huang-maddison-ea-2016" id="id30">[Silver et al., 2016]</a> for a description of how to
achieve this in AlphaGo. In a nutshell, reinforcement learning works
best if plenty of (state, action, reward)triples are available, i.e.,
whenever it is possible to try out lots of things to learn how they
relate to each other. Simulation provides such an avenue.</p></li>
<li><p>Deep Learning frameworks have played a crucial role in disseminating
ideas. The first generation of frameworks allowing for easy modeling
encompassed <a class="reference external" href="https://github.com/BVLC/caffe">Caffe</a>,
<a class="reference external" href="https://github.com/torch">Torch</a>, and
<a class="reference external" href="https://github.com/Theano/Theano">Theano</a>. Many seminal papers
were written using these tools. By now, they have been superseded by
<a class="reference external" href="https://github.com/tensorflow/tensorflow">TensorFlow</a>, often used
via its high level API
<a class="reference external" href="https://github.com/keras-team/keras">Keras</a>,
<a class="reference external" href="https://github.com/Microsoft/CNTK">CNTK</a>, <a class="reference external" href="https://github.com/caffe2/caffe2">Caffe
2</a>, and <a class="reference external" href="https://github.com/apache/incubator-mxnet">Apache
MxNet</a>. The third
generation of tools, namely imperative tools for deep learning, was
arguably spearheaded by
<a class="reference external" href="https://github.com/chainer/chainer">Chainer</a>, which used a syntax
similar to Python NumPy to describe models. This idea was adopted by
<a class="reference external" href="https://github.com/pytorch/pytorch">PyTorch</a> and the <a class="reference external" href="https://github.com/apache/incubator-mxnet">Gluon
API</a> of MXNet. It is
the latter group that this course uses to teach deep learning.</p></li>
</ul>
<p>The division of labor between systems researchers building better tools
and statistical modelers building better networks has greatly simplified
things. For instance, training a linear logistic regression model used
to be a nontrivial homework problem, worthy to give to new machine
learning PhD students at Carnegie Mellon University in 2014. By now,
this task can be accomplished with less than 10 lines of code, putting
it firmly into the grasp of programmers.</p>
</div>
<div class="section" id="id31">
<h2><span class="section-number">1.6. </span>قصص النجاح<a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h2>
<p>Artificial Intelligence has a long history of delivering results that
would be difficult to accomplish otherwise. For instance, mail is sorted
using optical character recognition. These systems have been deployed
since the 90s (this is, after all, the source of the famous MNIST and
USPS sets of handwritten digits). The same applies to reading checks for
bank deposits and scoring creditworthiness of applicants. Financial
transactions are checked for fraud automatically. This forms the
backbone of many e-commerce payment systems, such as PayPal, Stripe,
AliPay, WeChat, Apple, Visa, MasterCard. Computer programs for chess
have been competitive for decades. Machine learning feeds search,
recommendation, personalization and ranking on the Internet. In other
words, artificial intelligence and machine learning are pervasive,
albeit often hidden from sight.</p>
<p>It is only recently that AI has been in the limelight, mostly due to
solutions to problems that were considered intractable previously.</p>
<ul class="simple">
<li><p>Intelligent assistants, such as Apple’s Siri, Amazon’s Alexa, or
Google’s assistant are able to answer spoken questions with a
reasonable degree of accuracy. This includes menial tasks such as
turning on light switches (a boon to the disabled) up to making
barber’s appointments and offering phone support dialog. This is
likely the most noticeable sign that AI is affecting our lives.</p></li>
<li><p>A key ingredient in digital assistants is the ability to recognize
speech accurately. Gradually the accuracy of such systems has
increased to the point where they reach human parity
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#xiong-wu-alleva-ea-2018" id="id32">[Xiong et al., 2018]</a> for certain applications.</p></li>
<li><p>Object recognition likewise has come a long way. Estimating the
object in a picture was a fairly challenging task in 2010. On the
ImageNet benchmark <a class="bibtex reference internal" href="../chapter_references/zreferences.html#lin-lv-zhu-ea-2010" id="id33">[Lin et al., 2010]</a> achieved a top-5
error rate of 28%. By 2017, <a class="bibtex reference internal" href="../chapter_references/zreferences.html#hu-shen-sun-2018" id="id34">[Hu et al., 2018]</a> reduced this
error rate to 2.25%. Similarly stunning results have been achieved
for identifying birds, or diagnosing skin cancer.</p></li>
<li><p>Games used to be a bastion of human intelligence. Starting from
TDGammon [23], a program for playing Backgammon using temporal
difference (TD) reinforcement learning, algorithmic and computational
progress has led to algorithms for a wide range of applications.
Unlike Backgammon, chess has a much more complex state space and set
of actions. DeepBlue beat Gary Kasparov, Campbell et al.
<a class="bibtex reference internal" href="../chapter_references/zreferences.html#campbell-hoane-jr-hsu-2002" id="id35">[Campbell et al., 2002]</a>, using massive parallelism,
special purpose hardware and efficient search through the game tree.
Go is more difficult still, due to its huge state space. AlphaGo
reached human parity in 2015, <a class="bibtex reference internal" href="../chapter_references/zreferences.html#silver-huang-maddison-ea-2016" id="id36">[Silver et al., 2016]</a>
using Deep Learning combined with Monte Carlo tree sampling. The
challenge in Poker was that the state space is large and it is not
fully observed (we do not know the opponents’ cards). Libratus
exceeded human performance in Poker using efficiently structured
strategies <a class="bibtex reference internal" href="../chapter_references/zreferences.html#brown-sandholm-2017" id="id37">[Brown &amp; Sandholm, 2017]</a>. This illustrates the
impressive progress in games and the fact that advanced algorithms
played a crucial part in them.</p></li>
<li><p>Another indication of progress in AI is the advent of self-driving
cars and trucks. While full autonomy is not quite within reach yet,
excellent progress has been made in this direction, with companies
such as Tesla, NVIDIA, and Waymo shipping products that enable at
least partial autonomy. What makes full autonomy so challenging is
that proper driving requires the ability to perceive, to reason and
to incorporate rules into a system. At present, deep learning is used
primarily in the computer vision aspect of these problems. The rest
is heavily tuned by engineers.</p></li>
</ul>
<p>Again, the above list barely scratches the surface of where machine
learning has impacted practical applications. For instance, robotics,
logistics, computational biology, particle physics, and astronomy owe
some of their most impressive recent advances at least in parts to
machine learning. ML is thus becoming a ubiquitous tool for engineers
and scientists.</p>
<p>Frequently, the question of the AI apocalypse, or the AI singularity has
been raised in non-technical articles on AI. The fear is that somehow
machine learning systems will become sentient and decide independently
from their programmers (and masters) about things that directly affect
the livelihood of humans. To some extent, AI already affects the
livelihood of humans in an immediate way—creditworthiness is assessed
automatically, autopilots mostly navigate cars, decisions about whether
to grant bail use statistical data as input. More frivolously, we can
ask Alexa to switch on the coffee machine.</p>
<p>Fortunately, we are far from a sentient AI system that is ready to
manipulate its human creators (or burn their coffee). First, AI systems
are engineered, trained and deployed in a specific, goal-oriented
manner. While their behavior might give the illusion of general
intelligence, it is a combination of rules, heuristics and statistical
models that underlie the design. Second, at present tools for
<em>artificial general intelligence</em> simply do not exist that are able to
improve themselves, reason about themselves, and that are able to
modify, extend and improve their own architecture while trying to solve
general tasks.</p>
<p>A much more pressing concern is how AI is being used in our daily lives.
It is likely that many menial tasks fulfilled by truck drivers and shop
assistants can and will be automated. Farm robots will likely reduce the
cost for organic farming but they will also automate harvesting
operations. This phase of the industrial revolution may have profound
consequences on large swaths of society (truck drivers and shop
assistants are some of the most common jobs in many states).
Furthermore, statistical models, when applied without care can lead to
racial, gender or age bias and raise reasonable concerns about
procedural fairness if automated to drive consequential decisions. It is
important to ensure that these algorithms are used with care. With what
we know today, this strikes us a much more pressing concern than the
potential of malevolent superintelligence to destroy humanity.</p>
</div>
<div class="section" id="id38">
<h2><span class="section-number">1.7. </span>الملخّص<a class="headerlink" href="#id38" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Machine learning studies how computer systems can leverage
<em>experience</em> (often data) to improve performance at specific tasks.
It combines ideas from statistics, data mining, artificial
intelligence, and optimization. Often, it is used as a means of
implementing artificially-intelligent solutions.</p></li>
<li><p>As a class of machine learning, representational learning focuses on
how to automatically find the appropriate way to represent data. This
is often accomplished by a progression of learned transformations.</p></li>
<li><p>Much of the recent progress in deep learning has been triggered by an
abundance of data arising from cheap sensors and Internet-scale
applications, and by significant progress in computation, mostly
through GPUs.</p></li>
<li><p>Whole system optimization is a key component in obtaining good
performance. The availability of efficient deep learning frameworks
has made design and implementation of this significantly easier.</p></li>
</ul>
</div>
<div class="section" id="id39">
<h2><span class="section-number">1.8. </span>تمارين<a class="headerlink" href="#id39" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Which parts of code that you are currently writing could be
“learned”, i.e., improved by learning and automatically determining
design choices that are made in your code? Does your code include
heuristic design choices?</p></li>
<li><p>Which problems that you encounter have many examples for how to solve
them, yet no specific way to automate them? These may be prime
candidates for using deep learning.</p></li>
<li><p>Viewing the development of artificial intelligence as a new
industrial revolution, what is the relationship between algorithms
and data? Is it similar to steam engines and coal (what is the
fundamental difference)?</p></li>
<li><p>Where else can you apply the end-to-end training approach? Physics?
Engineering? Econometrics?</p></li>
</ol>
</div>
<div class="section" id="id40">
<h2><span class="section-number">1.9. </span><a class="reference external" href="https://discuss.mxnet.io/t/2310">مناقشات</a><a class="headerlink" href="#id40" title="Permalink to this headline">¶</a></h2>
<p><img alt="image0" src="../_images/qr_introduction.svg" /></p>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">1. مقدّمة</a><ul>
<li><a class="reference internal" href="#id2">1.1. مثال تحفيزي</a></li>
<li><a class="reference internal" href="#id3">1.2. المكوّنات الرّئيسية: البيانات والنماذج والخوارزميات</a><ul>
<li><a class="reference internal" href="#id4">1.2.1. البيانات</a></li>
<li><a class="reference internal" href="#id7">1.2.2. النّماذج</a></li>
<li><a class="reference internal" href="#id8">1.2.3. دالّة الهدف</a></li>
<li><a class="reference internal" href="#id9">1.2.4. خوارزميات التّحسين</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id10">1.3. أنواع التعلّم الآلى</a><ul>
<li><a class="reference internal" href="#id11">1.3.1. التعلّم تحت الإشراف</a><ul>
<li><a class="reference internal" href="#regression">1.3.1.1. Regression</a></li>
<li><a class="reference internal" href="#id12">1.3.1.2. التّصنيف</a></li>
<li><a class="reference internal" href="#tagging">1.3.1.3. Tagging</a></li>
<li><a class="reference internal" href="#search-and-ranking">1.3.1.4. Search and ranking</a></li>
<li><a class="reference internal" href="#recommender-systems">1.3.1.5. Recommender systems</a></li>
<li><a class="reference internal" href="#sequence-learning">1.3.1.6. Sequence Learning</a></li>
</ul>
</li>
<li><a class="reference internal" href="#unsupervised-learning">1.3.2. Unsupervised learning</a></li>
<li><a class="reference internal" href="#interacting-with-an-environment">1.3.3. Interacting with an Environment</a></li>
<li><a class="reference internal" href="#reinforcement-learning">1.3.4. Reinforcement learning</a><ul>
<li><a class="reference internal" href="#mdps-bandits-and-friends">1.3.4.1. MDPs, bandits, and friends</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#roots">1.4. Roots</a></li>
<li><a class="reference internal" href="#id14">1.5. الطريق إلى التعلم العميق</a></li>
<li><a class="reference internal" href="#id31">1.6. قصص النجاح</a></li>
<li><a class="reference internal" href="#id38">1.7. الملخّص</a></li>
<li><a class="reference internal" href="#id39">1.8. تمارين</a></li>
<li><a class="reference internal" href="#id40">1.9. مناقشات</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
     <a id="button-prev" href="../chapter_notation/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="P">
         <i class="pagenation-arrow-L fas fa-arrow-left fa-lg"></i>
         <div class="pagenation-text">
            <span class="pagenation-direction">Previous</span>
            <div>الّرموز</div>
         </div>
     </a>
     <a id="button-next" href="../chapter_preliminaries/index.html" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--colored" role="botton" accesskey="N">
         <i class="pagenation-arrow-R fas fa-arrow-right fa-lg"></i>
        <div class="pagenation-text">
            <span class="pagenation-direction">Next</span>
            <div>2. التمهيدات</div>
        </div>
     </a>
  </div>
        
        </main>
    </div>
  </body>
</html>